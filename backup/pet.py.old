# pet.py - è™šæ‹Ÿå® ç‰©ç±»
import random
import json
import time
import os
from datetime import datetime, timedelta
from enum import Enum
import numpy as np
from collections import defaultdict, Counter

class PetState(Enum):
    """å® ç‰©çŠ¶æ€æšä¸¾"""
    EGG = "è›‹"
    BABY = "å¹¼å¹´"
    CHILD = "ç«¥å¹´"
    TEEN = "é’å°‘å¹´"
    ADULT = "æˆå¹´"
    ELDER = "è€å¹´"

class PetMood(Enum):
    """å® ç‰©å¿ƒæƒ…æšä¸¾"""
    ECSTATIC = "ç‹‚å–œ"
    HAPPY = "å¿«ä¹"
    CONTENT = "æ»¡è¶³"
    NEUTRAL = "ä¸€èˆ¬"
    SAD = "æ‚²ä¼¤"
    DEPRESSED = "æŠ‘éƒ"
    ANGRY = "ç”Ÿæ°”"

class PetPersonality(Enum):
    """å® ç‰©æ€§æ ¼ç±»å‹"""
    PLAYFUL = "é¡½çš®"      # å–œæ¬¢ç©è€
    LAZY = "æ‡’æƒ°"        # å–œæ¬¢ä¼‘æ¯
    HUNGRY = "è´ªåƒ"      # å®¹æ˜“é¥¿
    CLEAN = "çˆ±å¹²å‡€"     # è®¨åŒè„ä¹±
    AFFECTIONATE = "é»äºº" # éœ€è¦å…³æ³¨
    INDEPENDENT = "ç‹¬ç«‹" # å–œæ¬¢ç‹¬å¤„
    CURIOUS = "å¥½å¥‡"     # å–œæ¬¢æ¢ç´¢

class EmotionType(Enum):
    """æƒ…æ„Ÿç±»å‹æšä¸¾"""
    JOY = "æ„‰æ‚¦"
    EXCITEMENT = "å…´å¥‹"
    CALM = "å¹³é™"
    ANXIETY = "ç„¦è™‘"
    FEAR = "ææƒ§"
    ANGER = "æ„¤æ€’"
    SADNESS = "æ‚²ä¼¤"
    LOVE = "å–œçˆ±"
    CURIOSITY = "å¥½å¥‡"

class EmotionEvent:
    """æƒ…æ„Ÿäº‹ä»¶"""
    def __init__(self, emotion_type, intensity, trigger, timestamp=None):
        self.emotion_type = emotion_type
        self.intensity = intensity  # 0.0-1.0
        self.trigger = trigger      # è§¦å‘åŸå› 
        self.timestamp = timestamp or datetime.now()
    
    def to_dict(self):
        return {
            "emotion_type": self.emotion_type.value,
            "intensity": self.intensity,
            "trigger": self.trigger,
            "timestamp": self.timestamp.strftime("%Y-%m-%d %H:%M:%S")
        }
    
    @classmethod
    def from_dict(cls, data):
        emotion_type = EmotionType(data["emotion_type"])
        intensity = data["intensity"]
        trigger = data["trigger"]
        timestamp = datetime.strptime(data["timestamp"], "%Y-%m-%d %H:%M:%S")
        return cls(emotion_type, intensity, trigger, timestamp)

class EmotionalSystem:
    """æƒ…æ„Ÿç³»ç»Ÿ"""
    def __init__(self, pet):
        self.pet = pet
        
        # æƒ…æ„Ÿç»´åº¦ï¼ˆ0.0-1.0ï¼‰
        self.emotions = {
            EmotionType.JOY: 0.5,
            EmotionType.EXCITEMENT: 0.3,
            EmotionType.CALM: 0.6,
            EmotionType.ANXIETY: 0.1,
            EmotionType.FEAR: 0.1,
            EmotionType.ANGER: 0.1,
            EmotionType.SADNESS: 0.1,
            EmotionType.LOVE: 0.5,
            EmotionType.CURIOSITY: 0.4
        }
        
        # æƒ…æ„Ÿå†å²
        self.emotion_history = []
        self.max_history_length = 100
        
        # æƒ…æ„Ÿè§¦å‘è®°å¿†
        self.emotion_triggers = defaultdict(list)
        
        # æƒ…æ„Ÿè¡°å‡ç‡ï¼ˆæ¯å°æ—¶ï¼‰
        self.decay_rates = {
            EmotionType.JOY: 0.05,
            EmotionType.EXCITEMENT: 0.1,
            EmotionType.CALM: 0.02,
            EmotionType.ANXIETY: 0.08,
            EmotionType.FEAR: 0.15,
            EmotionType.ANGER: 0.1,
            EmotionType.SADNESS: 0.06,
            EmotionType.LOVE: 0.03,
            EmotionType.CURIOSITY: 0.07
        }
        
        # æƒ…æ„Ÿä¼ æŸ“ç³»æ•°
        self.contagion_coefficient = 0.3
        
        # æƒ…æ„Ÿé˜ˆå€¼
        self.emotion_thresholds = {
            "high": 0.7,
            "medium": 0.4,
            "low": 0.2
        }
        
        print("ğŸ’– æƒ…æ„Ÿç³»ç»Ÿå·²åˆå§‹åŒ–ï¼")
    
    def trigger_emotion(self, emotion_type, intensity, trigger):
        """è§¦å‘æƒ…æ„Ÿ"""
        # é™åˆ¶å¼ºåº¦èŒƒå›´
        intensity = max(0.0, min(1.0, intensity))
        
        # æ›´æ–°æƒ…æ„Ÿå¼ºåº¦
        old_intensity = self.emotions[emotion_type]
        self.emotions[emotion_type] = min(1.0, self.emotions[emotion_type] + intensity)
        
        # è®°å½•æƒ…æ„Ÿäº‹ä»¶
        event = EmotionEvent(emotion_type, intensity, trigger)
        self.emotion_history.append(event)
        
        # è®°å½•æƒ…æ„Ÿè§¦å‘
        self.emotion_triggers[emotion_type].append(trigger)
        
        # é™åˆ¶å†å²é•¿åº¦
        if len(self.emotion_history) > self.max_history_length:
            self.emotion_history.pop(0)
        
        # æƒ…æ„Ÿä¼ æŸ“ï¼šå½±å“å…¶ä»–æƒ…æ„Ÿ
        self._apply_emotion_contagion(emotion_type, intensity)
        
        # æ›´æ–°å® ç‰©å¿ƒæƒ…
        self._update_mood_from_emotions()
        
        return self.emotions[emotion_type] - old_intensity
    
    def _apply_emotion_contagion(self, emotion_type, intensity):
        """åº”ç”¨æƒ…æ„Ÿä¼ æŸ“"""
        # å®šä¹‰æƒ…æ„Ÿä¼ æŸ“è§„åˆ™
        contagion_rules = {
            EmotionType.JOY: {EmotionType.EXCITEMENT: 0.5, EmotionType.LOVE: 0.3},
            EmotionType.EXCITEMENT: {EmotionType.JOY: 0.4, EmotionType.CURIOSITY: 0.3},
            EmotionType.ANXIETY: {EmotionType.FEAR: 0.6, EmotionType.ANGER: 0.4},
            EmotionType.FEAR: {EmotionType.ANXIETY: 0.7, EmotionType.SADNESS: 0.3},
            EmotionType.ANGER: {EmotionType.ANXIETY: 0.5, EmotionType.FEAR: 0.2},
            EmotionType.SADNESS: {EmotionType.ANXIETY: 0.4, EmotionType.FEAR: 0.2},
            EmotionType.LOVE: {EmotionType.JOY: 0.6, EmotionType.CALM: 0.4},
            EmotionType.CURIOSITY: {EmotionType.EXCITEMENT: 0.5, EmotionType.JOY: 0.3}
        }
        
        if emotion_type in contagion_rules:
            for target_emotion, contagion_factor in contagion_rules[emotion_type].items():
                contagion_amount = intensity * self.contagion_coefficient * contagion_factor
                self.emotions[target_emotion] = min(1.0, self.emotions[target_emotion] + contagion_amount)
    
    def _update_mood_from_emotions(self):
        """æ ¹æ®æƒ…æ„Ÿæ›´æ–°å¿ƒæƒ…"""
        # è®¡ç®—ç§¯ææƒ…æ„Ÿå’Œæ¶ˆææƒ…æ„Ÿçš„å¹³è¡¡
        positive_emotions = [
            self.emotions[EmotionType.JOY],
            self.emotions[EmotionType.EXCITEMENT],
            self.emotions[EmotionType.CALM],
            self.emotions[EmotionType.LOVE],
            self.emotions[EmotionType.CURIOSITY]
        ]
        
        negative_emotions = [
            self.emotions[EmotionType.ANXIETY],
            self.emotions[EmotionType.FEAR],
            self.emotions[EmotionType.ANGER],
            self.emotions[EmotionType.SADNESS]
        ]
        
        positive_score = sum(positive_emotions) / len(positive_emotions)
        negative_score = sum(negative_emotions) / len(negative_emotions)
        
        # æ ¹æ®æƒ…æ„Ÿå¹³è¡¡ç¡®å®šå¿ƒæƒ…
        mood_score = positive_score - negative_score
        
        if mood_score >= 0.6:
            self.pet.mood = PetMood.ECSTATIC
        elif mood_score >= 0.3:
            self.pet.mood = PetMood.HAPPY
        elif mood_score >= 0.1:
            self.pet.mood = PetMood.CONTENT
        elif mood_score >= -0.1:
            self.pet.mood = PetMood.NEUTRAL
        elif mood_score >= -0.3:
            self.pet.mood = PetMood.SAD
        elif mood_score >= -0.6:
            self.pet.mood = PetMood.DEPRESSED
        else:
            self.pet.mood = PetMood.ANGRY
    
    def update_emotions(self, hours_passed):
        """æ›´æ–°æƒ…æ„Ÿï¼ˆéšæ—¶é—´è¡°å‡ï¼‰"""
        for emotion_type, decay_rate in self.decay_rates.items():
            # æƒ…æ„Ÿè¡°å‡
            decay_amount = decay_rate * hours_passed
            self.emotions[emotion_type] = max(0.1, self.emotions[emotion_type] - decay_amount)
        
        # æ›´æ–°å¿ƒæƒ…
        self._update_mood_from_emotions()
    
    def get_dominant_emotion(self):
        """è·å–ä¸»å¯¼æƒ…æ„Ÿ"""
        return max(self.emotions, key=self.emotions.get)
    
    def get_emotion_state(self):
        """è·å–æƒ…æ„ŸçŠ¶æ€"""
        dominant = self.get_dominant_emotion()
        return {
            "dominant_emotion": dominant.value,
            "dominant_intensity": self.emotions[dominant],
            "all_emotions": {e.value: intensity for e, intensity in self.emotions.items()},
            "mood": self.pet.mood.value
        }
    
    def get_emotional_influence(self):
        """è·å–æƒ…æ„Ÿå¯¹è¡Œä¸ºçš„å½±å“"""
        influence = {}
        
        # æ„‰æ‚¦å¢åŠ å¿«ä¹åº¦
        influence["happiness_bonus"] = (self.emotions[EmotionType.JOY] * 20)
        
        # ç„¦è™‘é™ä½å¿«ä¹åº¦
        influence["happiness_penalty"] = (self.emotions[EmotionType.ANXIETY] * 15)
        
        # å…´å¥‹å¢åŠ èƒ½é‡æ¶ˆè€—
        influence["energy_bonus"] = (self.emotions[EmotionType.EXCITEMENT] * 10)
        
        # å¹³é™é™ä½èƒ½é‡æ¶ˆè€—
        influence["energy_saving"] = (self.emotions[EmotionType.CALM] * 5)
        
        # æ„¤æ€’å¢åŠ é¥¥é¥¿
        influence["hunger_increase"] = (self.emotions[EmotionType.ANGER] * 5)
        
        # å¥½å¥‡å¢åŠ æ¢ç´¢æ¬²æœ›
        influence["exploration_desire"] = (self.emotions[EmotionType.CURIOSITY] * 15)
        
        return influence
    
    def save_emotional_data(self):
        """ä¿å­˜æƒ…æ„Ÿæ•°æ®"""
        return {
            "emotions": {e.value: intensity for e, intensity in self.emotions.items()},
            "emotion_history": [event.to_dict() for event in self.emotion_history],
            "emotion_triggers": {e.value: triggers for e, triggers in self.emotion_triggers.items()}
        }
    
    def load_emotional_data(self, data):
        """åŠ è½½æƒ…æ„Ÿæ•°æ®"""
        # æ¢å¤æƒ…æ„Ÿ
        self.emotions = {}
        for emotion_str, intensity in data.get("emotions", {}).items():
            emotion_type = EmotionType(emotion_str)
            self.emotions[emotion_type] = intensity
        
        # æ¢å¤æƒ…æ„Ÿå†å²
        self.emotion_history = []
        for event_data in data.get("emotion_history", []):
            event = EmotionEvent.from_dict(event_data)
            self.emotion_history.append(event)
        
        # æ¢å¤æƒ…æ„Ÿè§¦å‘
        self.emotion_triggers = defaultdict(list)
        for emotion_str, triggers in data.get("emotion_triggers", {}).items():
            emotion_type = EmotionType(emotion_str)
            self.emotion_triggers[emotion_type] = triggers

class VirtualPet:
    def __init__(self, name="æœªå‘½å", species="æœªçŸ¥"):
        # åŸºç¡€ä¿¡æ¯
        self.name = name
        self.species = species  # å¯æ‰©å±•ä¸ºä¸åŒç‰©ç§
        self.birthday = datetime.now()
        self.age_in_days = 0
        
        # çŠ¶æ€ç³»ç»Ÿ
        self.state = PetState.EGG
        self.mood = PetMood.NEUTRAL
        self.health = 100.0
        self.hunger = 0.0        # 0-100ï¼Œè¶Šé«˜è¶Šé¥¿
        self.energy = 100.0      # 0-100
        self.hygiene = 100.0     # 0-100ï¼Œè¶Šä½è¶Šè„
        self.happiness = 50.0    # 0-100
        self.weight = 1.0        # å…¬æ–¤
        
        # æ€§æ ¼ç³»ç»Ÿï¼ˆéšæœºç”Ÿæˆæˆ–é—ä¼ ï¼‰
        self.personality_traits = self._generate_personality()
        self.favorite_activities = []
        self.dislikes = []
        
        # æˆé•¿ç³»ç»Ÿ
        self.experience = 0
        self.level = 1
        self.skills = {
            "intelligence": 1,   # æ™ºåŠ›
            "strength": 1,       # åŠ›é‡
            "speed": 1,          # é€Ÿåº¦
            "social": 1,         # ç¤¾äº¤
        }
        
        # è®°å¿†ä¸å…³ç³»
        self.memories = []       # é‡å¤§äº‹ä»¶è®°å¿†
        self.relationship_with_owner = 50  # 0-100
        self.routine_preferences = defaultdict(int)
        
        # å¤–è§‚ç‰¹å¾ï¼ˆéšæœºç”Ÿæˆï¼‰
        self.color = random.choice(["ç™½è‰²", "æ£•è‰²", "é»‘è‰²", "æ–‘ç‚¹", "æ¡çº¹"])
        self.size = "å¾®å°"
        self.accessories = []    # è£…é¥°å“
        
        # æ—¶é—´è¿½è¸ª
        self.last_update_time = time.time()
        self.needs_update = True
        
        # ç‰¹æ®ŠçŠ¶æ€
        self.is_sleeping = False
        self.is_sick = False
        self.sickness_type = None
        
        # ç¡çœ ç›¸å…³å±æ€§
        self.sleep_start_time = None  # ç¡çœ å¼€å§‹æ—¶é—´
        self.sleep_duration = 0  # ç¡çœ æ—¶é•¿ï¼ˆå°æ—¶ï¼‰
        self.sleep_quality = "æ™®é€š"  # ç¡çœ è´¨é‡
        
        # æƒ…æ„Ÿç³»ç»Ÿ
        self.emotional_system = EmotionalSystem(self)
        
        print(f"âœ¨ æ–°å® ç‰© {name} è¯ç”Ÿäº†ï¼")
    
    def _generate_personality(self):
        """ç”Ÿæˆéšæœºæ€§æ ¼ç»„åˆ"""
        all_traits = list(PetPersonality)
        # éšæœºé€‰æ‹©2-3ä¸ªä¸»è¦æ€§æ ¼ç‰¹å¾
        num_traits = random.randint(2, 3)
        selected = random.sample(all_traits, num_traits)
        
        # ä¸ºæ¯ä¸ªç‰¹å¾åˆ†é…å¼ºåº¦
        traits = {}
        for trait in selected:
            traits[trait] = random.uniform(0.7, 1.0)
        
        # å¯èƒ½æœ‰ä¸€ä¸ªå¼±ç‰¹å¾
        if random.random() < 0.3:
            weak_trait = random.choice([t for t in all_traits if t not in selected])
            traits[weak_trait] = random.uniform(0.3, 0.5)
        
        return traits
    
    def update(self, current_time=None):
        """æ›´æ–°å® ç‰©çŠ¶æ€ï¼ˆéšæ—¶é—´å˜åŒ–ï¼‰"""
        if current_time is None:
            current_time = time.time()
        
        # è®¡ç®—æ—¶é—´å·®ï¼ˆç§’ï¼‰
        time_passed = current_time - self.last_update_time
        hours_passed = time_passed / 3600  # è½¬æ¢ä¸ºå°æ—¶
        
        # é˜²æ­¢æ—¶é—´è·³è·ƒè¿‡å¤§
        if hours_passed > 24:
            hours_passed = 24
        
        # æ›´æ–°åŸºæœ¬éœ€æ±‚ï¼ˆæ¯å°æ—¶å˜åŒ–ï¼‰
        self._update_needs(hours_passed)
        
        # æ›´æ–°å¹´é¾„
        self._update_age()
        
        # æ›´æ–°å¿ƒæƒ…
        self._update_mood()
        
        # æ£€æŸ¥å¥åº·çŠ¶æ€
        self._check_health()
        
        # æ›´æ–°æˆé•¿çŠ¶æ€
        self._update_growth()
        
        self.last_update_time = current_time
        self.needs_update = False
    
    def _update_needs(self, hours_passed):
        """éšæ—¶é—´æ›´æ–°éœ€æ±‚å€¼"""
        # é¥¥é¥¿å¢é•¿ï¼ˆæ ¹æ®æ€§æ ¼è°ƒæ•´ï¼‰
        hunger_rate = 3.0  # æ¯å°æ—¶é¥¥é¥¿å¢é•¿
        
        # è´ªåƒæ€§æ ¼é¥¿å¾—æ›´å¿«
        if PetPersonality.HUNGRY in self.personality_traits:
            hunger_rate *= 1.5
        
        self.hunger = min(100, self.hunger + hunger_rate * hours_passed)
        
        # èƒ½é‡æ¢å¤æˆ–æ¶ˆè€—
        if self.is_sleeping:
            # ç¡çœ æ—¶æ¢å¤èƒ½é‡
            energy_rate = 15.0  # æ¯å°æ—¶æ¢å¤
            old_energy = self.energy
            self.energy = min(100, self.energy + energy_rate * hours_passed)
            
            # å½“èƒ½é‡è¾¾åˆ°100%æ—¶è‡ªåŠ¨é†’æ¥
            if self.energy >= 100:
                self.wake_up()
        else:
            # æ´»è·ƒæ—¶æ¶ˆè€—èƒ½é‡
            energy_rate = 2.0  # æ¯å°æ—¶æ¶ˆè€—
            self.energy = max(0, self.energy - energy_rate * hours_passed)
        
        # æ¸…æ´åº¦ä¸‹é™ï¼ˆé™¤éçˆ±å¹²å‡€æ€§æ ¼ï¼‰
        hygiene_rate = 1.0
        if PetPersonality.CLEAN in self.personality_traits:
            hygiene_rate *= 0.5  # çˆ±å¹²å‡€çš„å® ç‰©è„å¾—æ…¢
        
        self.hygiene = max(0, self.hygiene - hygiene_rate * hours_passed)
        
        # å¿«ä¹åº¦å—å…¶ä»–å› ç´ å½±å“
        happiness_change = 0
        
        # é¥¥é¥¿å½±å“å¿«ä¹
        if self.hunger > 70:
            happiness_change -= 0.5 * hours_passed
        elif self.hunger < 30:
            happiness_change += 0.2 * hours_passed
        
        # æ¸…æ´åº¦å½±å“å¿«ä¹
        if self.hygiene < 30:
            happiness_change -= 0.3 * hours_passed
        
        # èƒ½é‡å½±å“å¿«ä¹
        if self.energy < 20:
            happiness_change -= 0.4 * hours_passed
        
        # æ€§æ ¼å½±å“
        if PetPersonality.PLAYFUL in self.personality_traits and self.energy > 50:
            # ç²¾åŠ›å……æ²›çš„é¡½çš®å® ç‰©æ›´å¿«ä¹
            happiness_change += 0.1 * hours_passed
        
        # æƒ…æ„Ÿç³»ç»Ÿå½±å“
        emotional_influence = self.emotional_system.get_emotional_influence()
        happiness_change += emotional_influence["happiness_bonus"] * hours_passed
        happiness_change -= emotional_influence["happiness_penalty"] * hours_passed
        
        # èƒ½é‡å—æƒ…æ„Ÿå½±å“ï¼ˆç¡çœ æ—¶ä¸åº”ç”¨ï¼Œå› ä¸ºç¡çœ æ—¶èƒ½é‡æ¢å¤æ˜¯ä¸»è¦æœºåˆ¶ï¼‰
        if not self.is_sleeping:
            self.energy += emotional_influence["energy_bonus"] * hours_passed
            self.energy += emotional_influence["energy_saving"] * hours_passed
            self.energy = min(100, self.energy)
        
        # é¥¥é¥¿å—æƒ…æ„Ÿå½±å“
        self.hunger += emotional_influence["hunger_increase"] * hours_passed
        self.hunger = min(100, self.hunger)
        
        self.happiness = max(0, min(100, self.happiness + happiness_change))
        
        # æ›´æ–°æƒ…æ„Ÿç³»ç»Ÿ
        self.emotional_system.update_emotions(hours_passed)
    
    def _update_age(self):
        """æ›´æ–°å¹´é¾„å’Œç”Ÿå‘½å‘¨æœŸé˜¶æ®µ"""
        age_delta = datetime.now() - self.birthday
        self.age_in_days = age_delta.days
        
        # æ ¹æ®å¹´é¾„æ›´æ–°ç”Ÿå‘½é˜¶æ®µ
        if self.age_in_days < 2:
            self.state = PetState.EGG
        elif self.age_in_days < 10:
            self.state = PetState.BABY
        elif self.age_in_days < 30:
            self.state = PetState.CHILD
        elif self.age_in_days < 90:
            self.state = PetState.TEEN
        elif self.age_in_days < 365:
            self.state = PetState.ADULT
        else:
            self.state = PetState.ELDER
        
        # æ›´æ–°å¤§å°
        size_map = {
            PetState.EGG: "å¾®å°",
            PetState.BABY: "å¾ˆå°",
            PetState.CHILD: "å°",
            PetState.TEEN: "ä¸­ç­‰",
            PetState.ADULT: "å¤§",
            PetState.ELDER: "å¤§"
        }
        self.size = size_map.get(self.state, "ä¸­ç­‰")
    
    def _update_mood(self):
        """æ ¹æ®çŠ¶æ€è®¡ç®—å½“å‰å¿ƒæƒ…ï¼ˆç°åœ¨ç”±æƒ…æ„Ÿç³»ç»Ÿä¸»å¯¼ï¼‰"""
        # æƒ…æ„Ÿç³»ç»Ÿå·²ç»é€šè¿‡ update_emotions æ›´æ–°äº†å¿ƒæƒ…
        # è¿™é‡ŒåªåšåŸºç¡€çš„çŠ¶æ€æ£€æŸ¥ï¼Œç¡®ä¿å¿ƒæƒ…ä¸ä¼šè¿‡äºæç«¯
        pass
    
    def _check_health(self):
        """æ£€æŸ¥å¥åº·çŠ¶æ€"""
        health_penalty = 0
        
        # æç«¯é¥¥é¥¿ä¼¤å®³å¥åº·
        if self.hunger > 90:
            health_penalty += 0.5
        
        # è‚®è„ç¯å¢ƒå¯¼è‡´ç”Ÿç—…
        if self.hygiene < 10:
            health_penalty += 0.3
        
        # é•¿æœŸä¸å¿«ä¹å½±å“å¥åº·
        if self.happiness < 20:
            health_penalty += 0.2
        
        # åº”ç”¨å¥åº·å˜åŒ–
        self.health = max(0, self.health - health_penalty)
        
        # æ£€æŸ¥æ˜¯å¦ç”Ÿç—…
        if not self.is_sick:
            sick_chance = 0
            if self.hygiene < 15:
                sick_chance += 0.1
            if self.health < 30:
                sick_chance += 0.2
            if self.happiness < 20:
                sick_chance += 0.1
            
            if random.random() < sick_chance:
                self._get_sick()
        else:
            # å¦‚æœæ­£åœ¨ç”Ÿç—…ï¼Œæ¢å¤æˆ–æ¶åŒ–
            recovery_chance = 0.1
            if self.health > 70 and self.hygiene > 50:
                recovery_chance = 0.3
            
            if random.random() < recovery_chance:
                self._recover_from_sickness()
    
    def _get_sick(self):
        """å® ç‰©ç”Ÿç—…"""
        sickness_types = ["æ„Ÿå†’", "æ¶ˆåŒ–ä¸è‰¯", "çš®è‚¤ç—…", "ç–²åŠ³"]
        self.sickness_type = random.choice(sickness_types)
        self.is_sick = True
        self.health -= 10
        self._add_memory(f"ç”Ÿç—…äº†ï¼ˆ{self.sickness_type}ï¼‰")
    
    def _recover_from_sickness(self):
        """ä»ç–¾ç—…ä¸­æ¢å¤"""
        self.is_sick = False
        self.sickness_type = None
        self._add_memory("ä»ç–¾ç—…ä¸­æ¢å¤äº†")
    
    def _update_growth(self):
        """æ›´æ–°æˆé•¿å’ŒæŠ€èƒ½"""
        # æ ¹æ®æ´»åŠ¨å¢åŠ ç»éªŒ
        if self.happiness > 60:
            self.experience += 1
        
        # å‡çº§æ£€æŸ¥
        exp_needed = self.level * 100
        if self.experience >= exp_needed:
            self.level_up()
    
    def level_up(self):
        """å‡çº§å® ç‰©"""
        self.level += 1
        self.experience = 0
        
        # éšæœºæå‡ä¸€ä¸ªæŠ€èƒ½
        skill_to_up = random.choice(list(self.skills.keys()))
        self.skills[skill_to_up] += 1
        
        # æ¢å¤ä¸€äº›çŠ¶æ€
        self.health = min(100, self.health + 20)
        self.happiness = min(100, self.happiness + 30)
        
        self._add_memory(f"å‡åˆ°äº† {self.level} çº§ï¼{skill_to_up} æå‡äº†")
    
    def _add_memory(self, memory_text):
        """æ·»åŠ è®°å¿†"""
        memory = {
            "time": datetime.now().strftime("%Y-%m-%d %H:%M"),
            "text": memory_text,
            "age": self.age_in_days
        }
        self.memories.append(memory)
        
        # é™åˆ¶è®°å¿†æ•°é‡
        if len(self.memories) > 50:
            self.memories = self.memories[-50:]
    
    # ========== ç©å®¶äº¤äº’æ–¹æ³• ==========
    
    def feed(self, food_type="æ™®é€šé£Ÿç‰©"):
        """å–‚é£Ÿå® ç‰©"""
        # æ£€æŸ¥å® ç‰©æ˜¯å¦åœ¨ç¡è§‰
        was_sleeping = self.is_sleeping
        wake_result = ""
        
        if was_sleeping:
            # å”¤é†’å® ç‰©
            wake_result = self.wake_up()
        
        food_effects = {
            "æ™®é€šé£Ÿç‰©": {"hunger": -30, "happiness": 5, "weight": 0.1},
            "ç¾å‘³å¤§é¤": {"hunger": -50, "happiness": 15, "weight": 0.2},
            "å¥åº·é£Ÿå“": {"hunger": -25, "health": 10, "weight": 0.05},
            "é›¶é£Ÿ": {"hunger": -10, "happiness": 10, "weight": 0.02}
        }
        
        effect = food_effects.get(food_type, food_effects["æ™®é€šé£Ÿç‰©"])
        
        # åº”ç”¨æ•ˆæœ
        self.hunger = max(0, self.hunger + effect["hunger"])
        self.happiness = min(100, self.happiness + effect.get("happiness", 0))
        self.health = min(100, self.health + effect.get("health", 0))
        self.weight += effect.get("weight", 0)
        
        # è´ªåƒæ€§æ ¼é¢å¤–å¿«ä¹
        if PetPersonality.HUNGRY in self.personality_traits:
            self.happiness += 5
        
        # è§¦å‘æƒ…æ„Ÿ
        self.emotional_system.trigger_emotion(EmotionType.JOY, 0.3, f"åƒäº†{food_type}")
        if PetPersonality.HUNGRY in self.personality_traits:
            self.emotional_system.trigger_emotion(EmotionType.LOVE, 0.2, "ä¸»äººå–‚é£Ÿ")
        
        self._add_memory(f"åƒäº†{self.name}ä¸€ä»½{food_type}")
        
        # è®°å½•å–‚é£Ÿåå¥½
        self.routine_preferences["feed"] += 1
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦ç»§ç»­ç¡è§‰
        continue_sleep_result = ""
        if was_sleeping:
            # å¦‚æœä¹‹å‰åœ¨ç¡è§‰ï¼Œåƒå®Œé¥­å†ç»§ç»­ç¡è§‰
            continue_sleep_result = self.sleep()
        else:
            # æ£€æŸ¥ç²¾åŠ›å€¼ï¼Œå¦‚æœå°äº50%ï¼Œåˆ™å»ç¡è§‰
            continue_sleep_result = self._check_energy_and_sleep()
        
        # æ„å»ºè¿”å›æ¶ˆæ¯
        result_message = f"å–‚é£ŸæˆåŠŸï¼{self.name}çœ‹èµ·æ¥å¾ˆå¼€å¿ƒ"
        if wake_result:
            result_message = f"{wake_result}\n{result_message}"
        if continue_sleep_result:
            result_message = f"{result_message}\n{continue_sleep_result}"
        
        return result_message
    
    def play(self, game_type="æ™®é€šæ¸¸æˆ"):
        """å’Œå® ç‰©ç©è€"""
        if self.is_sleeping:
            return "å® ç‰©æ­£åœ¨ç¡è§‰ï¼Œæ— æ³•ç©è€"
        
        if self.energy < 20:
            return "å® ç‰©å¤ªç´¯äº†ï¼Œéœ€è¦ä¼‘æ¯"
        
        game_effects = {
            "æ™®é€šæ¸¸æˆ": {"energy": -15, "happiness": 20, "experience": 10},
            "æ¡çƒæ¸¸æˆ": {"energy": -20, "happiness": 25, "skills": ["strength", "speed"]},
            "æ™ºåŠ›æ¸¸æˆ": {"energy": -10, "happiness": 15, "skills": ["intelligence"]},
            "ç¤¾äº¤æ¸¸æˆ": {"energy": -5, "happiness": 30, "skills": ["social"]}
        }
        
        effect = game_effects.get(game_type, game_effects["æ™®é€šæ¸¸æˆ"])
        
        # åº”ç”¨æ•ˆæœ
        self.energy = max(0, self.energy + effect["energy"])
        self.happiness = min(100, self.happiness + effect["happiness"])
        self.experience += effect.get("experience", 0)
        
        # æå‡æŠ€èƒ½
        for skill in effect.get("skills", []):
            self.skills[skill] += 0.5
        
        # é¡½çš®æ€§æ ¼é¢å¤–å¿«ä¹
        if PetPersonality.PLAYFUL in self.personality_traits:
            self.happiness += 10
        
        # æ‡’æƒ°æ€§æ ¼æ¶ˆè€—æ›´å¤šèƒ½é‡
        if PetPersonality.LAZY in self.personality_traits:
            self.energy -= 5
        
        # è§¦å‘æƒ…æ„Ÿ
        self.emotional_system.trigger_emotion(EmotionType.EXCITEMENT, 0.4, f"ç©äº†{game_type}")
        self.emotional_system.trigger_emotion(EmotionType.JOY, 0.3, "ç©è€")
        if PetPersonality.PLAYFUL in self.personality_traits:
            self.emotional_system.trigger_emotion(EmotionType.CURIOSITY, 0.2, "æƒ³ç»§ç»­ç©")
        
        self._add_memory(f"ç©äº†{game_type}æ¸¸æˆ")
        
        # è®°å½•æ¸¸æˆåå¥½
        self.routine_preferences["play"] += 1
        
        # æ£€æŸ¥ç²¾åŠ›å€¼ï¼Œå¦‚æœå°äº50%ï¼Œåˆ™å»ç¡è§‰
        sleep_result = self._check_energy_and_sleep()
        if sleep_result:
            return f"ç©è€æˆåŠŸï¼{self.name}ç©å¾—å¾ˆå¼€å¿ƒ\n{sleep_result}"
        
        return f"ç©è€æˆåŠŸï¼{self.name}ç©å¾—å¾ˆå¼€å¿ƒ"
    
    def clean(self, clean_type="æ¯›å‘æ¸…ç†"):
        """æ¸…æ´å® ç‰©
        
        Args:
            clean_type: æ¸…æ´ç±»å‹ï¼Œå¯é€‰å€¼ï¼š"æ¯›å‘æ¸…ç†", "åˆ·ç‰™", "æ´—æ¾¡", "ä¿®å‰ªæŒ‡ç”²"
        """
        if self.is_sleeping:
            return "å® ç‰©æ­£åœ¨ç¡è§‰ï¼Œæ— æ³•æ¸…æ´"
        
        # ä¸åŒæ¸…æ´ç±»å‹çš„æ•ˆæœ
        clean_effects = {
            "æ¯›å‘æ¸…ç†": {
                "hygiene_gain": 40,
                "happiness_gain": 10,
                "health_gain": 5,
                "emotion": EmotionType.CALM,
                "emotion_intensity": 0.3,
                "description": "æ¸…ç†æ¯›å‘",
                "memory": "è¢«æ¸…ç†äº†æ¯›å‘"
            },
            "åˆ·ç‰™": {
                "hygiene_gain": 20,
                "happiness_gain": 5,
                "health_gain": 15,
                "emotion": EmotionType.ANXIETY,
                "emotion_intensity": 0.2,
                "description": "åˆ·ç‰™",
                "memory": "è¢«åˆ·äº†ç‰™"
            },
            "æ´—æ¾¡": {
                "hygiene_gain": 60,
                "happiness_gain": 15,
                "health_gain": 10,
                "emotion": EmotionType.EXCITEMENT,
                "emotion_intensity": 0.4,
                "description": "æ´—æ¾¡",
                "memory": "è¢«æ´—äº†æ¾¡"
            },
            "ä¿®å‰ªæŒ‡ç”²": {
                "hygiene_gain": 15,
                "happiness_gain": 5,
                "health_gain": 5,
                "emotion": EmotionType.ANXIETY,
                "emotion_intensity": 0.3,
                "description": "ä¿®å‰ªæŒ‡ç”²",
                "memory": "è¢«ä¿®å‰ªäº†æŒ‡ç”²"
            }
        }
        
        # è·å–å½“å‰æ¸…æ´ç±»å‹çš„æ•ˆæœ
        effect = clean_effects.get(clean_type, clean_effects["æ¯›å‘æ¸…ç†"])
        
        # åº”ç”¨æ•ˆæœ
        hygiene_gain = effect["hygiene_gain"]
        happiness_gain = effect["happiness_gain"]
        health_gain = effect["health_gain"]
        
        # çˆ±å¹²å‡€æ€§æ ¼æ›´äº«å—æ¸…æ´
        if PetPersonality.CLEAN in self.personality_traits:
            hygiene_gain *= 1.3
            happiness_gain *= 1.5
        
        # åº”ç”¨æ¸…æ´æ•ˆæœ
        self.hygiene = min(100, self.hygiene + hygiene_gain)
        self.happiness = min(100, self.happiness + happiness_gain)
        self.health = min(100, self.health + health_gain)
        
        # è§¦å‘æƒ…æ„Ÿ
        self.emotional_system.trigger_emotion(effect["emotion"], effect["emotion_intensity"], effect["description"])
        
        # çˆ±å¹²å‡€æ€§æ ¼é¢å¤–è§¦å‘å¿«ä¹æƒ…æ„Ÿ
        if PetPersonality.CLEAN in self.personality_traits:
            self.emotional_system.trigger_emotion(EmotionType.JOY, 0.4, "äº«å—æ¸…æ´")
        
        # æ·»åŠ è®°å¿†
        self._add_memory(effect["memory"])
        
        # ç”Ÿæˆæ¸…æ´ç»“æœæ¶ˆæ¯
        result_message = ""
        if PetPersonality.CLEAN in self.personality_traits:
            result_message = f"{clean_type}æˆåŠŸï¼{self.name}äº«å—äº†è¿™æ¬¡æ¸…æ´ï¼Œç°åœ¨çœ‹èµ·æ¥å¾ˆæ•´æ´"
        else:
            result_message = f"{clean_type}æˆåŠŸï¼{self.name}ç°åœ¨å¹²å‡€å¤šäº†"
        
        # æ£€æŸ¥ç²¾åŠ›å€¼ï¼Œå¦‚æœå°äº50%ï¼Œåˆ™å»ç¡è§‰
        sleep_result = self._check_energy_and_sleep()
        if sleep_result:
            return f"{result_message}\n{sleep_result}"
        
        return result_message
    
    def sleep(self):
        """è®©å® ç‰©ç¡è§‰"""
        if self.is_sleeping:
            return "å® ç‰©å·²ç»åœ¨ç¡è§‰äº†"
        
        self.is_sleeping = True
        self.sleep_start_time = time.time()
        self.sleep_duration = 0
        
        # æ ¹æ®æ€§æ ¼è°ƒæ•´ç¡çœ è¡Œä¸º
        sleep_message = f"{self.name}å¼€å§‹ç¡è§‰äº†ï¼Œæ™šå®‰ï¼"
        if PetPersonality.LAZY in self.personality_traits:
            sleep_message += f" (æ‡’æƒ°çš„{self.name}å¯èƒ½ä¼šç¡å¾ˆä¹…å“¦)"
        
        # è§¦å‘æƒ…æ„Ÿ
        self.emotional_system.trigger_emotion(EmotionType.CALM, 0.5, "å¼€å§‹ç¡è§‰")
        
        self._add_memory("å»ç¡è§‰äº†")
        return sleep_message
    
    def wake_up(self):
        """å«é†’å® ç‰©"""
        if not self.is_sleeping:
            return "å® ç‰©å·²ç»é†’ç€äº†"
        
        self.is_sleeping = False
        
        # è®¡ç®—ç¡çœ æ—¶é•¿
        if self.sleep_start_time:
            self.sleep_duration = (time.time() - self.sleep_start_time) / 3600  # è½¬æ¢ä¸ºå°æ—¶
        
        # è¯„ä¼°ç¡çœ è´¨é‡
        self._evaluate_sleep_quality()
        
        # é†’æ¥åçš„å¿ƒæƒ…å—ç¡çœ è´¨é‡å½±å“
        happiness_bonus = 0
        if self.energy > 80:
            happiness_bonus = 10
            wake_message = f"{self.name}ç²¾ç¥é¥±æ»¡åœ°é†’æ¥äº†ï¼"
        else:
            wake_message = f"{self.name}ç¡çœ¼æƒºå¿ªåœ°é†’æ¥äº†"
        
        # æ ¹æ®ç¡çœ è´¨é‡å¢åŠ é¢å¤–å¿«ä¹å€¼
        if self.sleep_quality == "ä¼˜ç§€":
            happiness_bonus += 5
            wake_message += f" (ç¡çœ è´¨é‡ä¼˜ç§€ï¼Œ{self.name}æ„Ÿè§‰éå¸¸å¥½ï¼)"
        elif self.sleep_quality == "è‰¯å¥½":
            happiness_bonus += 2
            wake_message += f" (ç¡çœ è´¨é‡è‰¯å¥½ï¼Œ{self.name}æ„Ÿè§‰ä¸é”™)"
        
        self.happiness = min(100, self.happiness + happiness_bonus)
        
        # è§¦å‘æƒ…æ„Ÿ
        if self.sleep_quality == "ä¼˜ç§€":
            self.emotional_system.trigger_emotion(EmotionType.JOY, 0.4, "ç¡å¾—å¾ˆå¥½")
        elif self.sleep_quality == "è‰¯å¥½":
            self.emotional_system.trigger_emotion(EmotionType.JOY, 0.2, "ç¡å¾—ä¸é”™")
        elif self.sleep_quality == "è¾ƒå·®":
            self.emotional_system.trigger_emotion(EmotionType.ANXIETY, 0.2, "æ²¡ç¡å¥½")
        
        # é‡ç½®ç¡çœ ç›¸å…³å±æ€§
        self.sleep_start_time = None
        
        memory = f"é†’æ¥äº†ï¼Œç¡çœ è´¨é‡ï¼š{self.sleep_quality}"
        self._add_memory(memory)
        return wake_message
    
    def _evaluate_sleep_quality(self):
        """è¯„ä¼°ç¡çœ è´¨é‡"""
        # åŸºäºç¡çœ æ—¶é•¿å’Œèƒ½é‡æ¢å¤æƒ…å†µè¯„ä¼°
        if self.sleep_duration >= 1 and self.energy >= 90:
            self.sleep_quality = "ä¼˜ç§€"
        elif self.sleep_duration >= 0.5 and self.energy >= 70:
            self.sleep_quality = "è‰¯å¥½"
        elif self.sleep_duration >= 0.2 and self.energy >= 50:
            self.sleep_quality = "æ™®é€š"
        else:
            self.sleep_quality = "è¾ƒå·®"
    
    def treat_sickness(self, medicine="æ™®é€šè¯ç‰©"):
        """æ²»ç–—å® ç‰©ç–¾ç—…"""
        if not self.is_sick:
            return "å® ç‰©æ²¡æœ‰ç”Ÿç—…"
        
        medicine_effects = {
            "æ™®é€šè¯ç‰©": {"health": 30, "recovery_chance": 0.5},
            "ç‰¹æ•ˆè¯": {"health": 50, "recovery_chance": 0.8},
            "è‡ªç„¶ç–—æ³•": {"health": 20, "happiness": 10, "recovery_chance": 0.4}
        }
        
        effect = medicine_effects.get(medicine, medicine_effects["æ™®é€šè¯ç‰©"])
        
        self.health = min(100, self.health + effect["health"])
        self.happiness += effect.get("happiness", 0)
        
        # æ£€æŸ¥æ˜¯å¦æ¢å¤
        if random.random() < effect["recovery_chance"]:
            self._recover_from_sickness()
            result = f"æ²»ç–—æˆåŠŸï¼{self.name}ä»{self.sickness_type}ä¸­æ¢å¤äº†"
            # è§¦å‘ç§¯ææƒ…æ„Ÿ
            self.emotional_system.trigger_emotion(EmotionType.JOY, 0.3, "ç–¾ç—…æ¢å¤")
            self.emotional_system.trigger_emotion(EmotionType.LOVE, 0.4, "ä¸»äººç…§é¡¾")
        else:
            result = f"æ²»ç–—æœ‰äº›æ•ˆæœï¼Œä½†{self.name}è¿˜éœ€è¦ä¼‘æ¯"
            # è§¦å‘ç„¦è™‘æƒ…æ„Ÿ
            self.emotional_system.trigger_emotion(EmotionType.ANXIETY, 0.2, "æ²»ç–—æ•ˆæœä¸ä½³")
        
        self._add_memory("æ¥å—äº†æ²»ç–—")
        return result
    
    def train(self, skill_type="intelligence"):
        """è®­ç»ƒå® ç‰©æŠ€èƒ½"""
        if self.is_sleeping:
            return "å® ç‰©æ­£åœ¨ç¡è§‰ï¼Œæ— æ³•è®­ç»ƒ"
        
        if self.energy < 30:
            return "å® ç‰©å¤ªç´¯äº†ï¼Œæ— æ³•è®­ç»ƒ"
        
        if skill_type not in self.skills:
            return f"æ— æ•ˆçš„æŠ€èƒ½ç±»å‹ï¼š{skill_type}"
        
        # è®­ç»ƒæ¶ˆè€—å’Œæ•ˆæœ
        energy_cost = 20
        skill_gain = 1
        
        # æ ¹æ®æ€§æ ¼è°ƒæ•´
        if PetPersonality.LAZY in self.personality_traits:
            energy_cost += 10
            self.happiness -= 5
        
        self.energy = max(0, self.energy - energy_cost)
        self.skills[skill_type] += skill_gain
        self.experience += 15
        self.happiness += 5
        
        # è§¦å‘æƒ…æ„Ÿ
        self.emotional_system.trigger_emotion(EmotionType.CURIOSITY, 0.3, "å­¦ä¹ æ–°æŠ€èƒ½")
        if PetPersonality.LAZY in self.personality_traits:
            self.emotional_system.trigger_emotion(EmotionType.ANXIETY, 0.2, "ä¸æƒ³è®­ç»ƒ")
        
        skill_names = {
            "intelligence": "æ™ºåŠ›",
            "strength": "åŠ›é‡",
            "speed": "é€Ÿåº¦",
            "social": "ç¤¾äº¤"
        }
        
        self._add_memory(f"è¿›è¡Œäº†{skill_names[skill_type]}è®­ç»ƒ")
        
        # æ£€æŸ¥ç²¾åŠ›å€¼ï¼Œå¦‚æœå°äº50%ï¼Œåˆ™å»ç¡è§‰
        sleep_result = self._check_energy_and_sleep()
        if sleep_result:
            return f"è®­ç»ƒæˆåŠŸï¼{self.name}çš„{skill_names[skill_type]}æå‡äº†\n{sleep_result}"
        
        return f"è®­ç»ƒæˆåŠŸï¼{self.name}çš„{skill_names[skill_type]}æå‡äº†"
    
    def change_color(self, new_color):
        """æ›´æ”¹å® ç‰©æ¯›å‘é¢œè‰²"""
        if self.is_sleeping:
            return "å® ç‰©æ­£åœ¨ç¡è§‰ï¼Œæ— æ³•æ›´æ”¹é¢œè‰²"
        
        available_colors = ["ç™½è‰²", "æ£•è‰²", "é»‘è‰²", "æ–‘ç‚¹", "æ¡çº¹", "é‡‘è‰²", "é“¶è‰²", "è“è‰²", "çº¢è‰²", "ç´«è‰²", "æ©˜è‰²", "æ¢¨èŠ±"]
        
        if new_color not in available_colors:
            return f"æ— æ•ˆçš„é¢œè‰²ã€‚å¯ç”¨é¢œè‰²ï¼š{', '.join(available_colors)}"
        
        old_color = self.color
        self.color = new_color
        self._add_memory(f"æ¯›å‘é¢œè‰²ä»{old_color}å˜æˆäº†{new_color}")
        
        return f"é¢œè‰²æ›´æ”¹æˆåŠŸï¼{self.name}ç°åœ¨æ˜¯{new_color}çš„äº†"
    
    def get_available_colors(self):
        """è·å–å¯ç”¨çš„é¢œè‰²åˆ—è¡¨"""
        return ["ç™½è‰²", "æ£•è‰²", "é»‘è‰²", "æ–‘ç‚¹", "æ¡çº¹", "é‡‘è‰²", "é“¶è‰²", "è“è‰²", "çº¢è‰²", "ç´«è‰²", "æ©˜è‰²", "æ¢¨èŠ±"]
    
    def get_status(self):
        """è·å–å® ç‰©çŠ¶æ€æ‘˜è¦"""
        needs_update = self.needs_update
        if needs_update:
            self.update()
        
        status = {
            "name": self.name,
            "species": self.species,
            "age": f"{self.age_in_days}å¤©",
            "state": self.state.value,
            "mood": self.mood.value,
            "level": self.level,
            "health": f"{self.health:.1f}/100",
            "hunger": f"{self.hunger:.1f}/100",
            "energy": f"{self.energy:.1f}/100",
            "hygiene": f"{self.hygiene:.1f}/100",
            "happiness": f"{self.happiness:.1f}/100",
            "weight": f"{self.weight:.1f}kg",
            "relationship": f"{self.relationship_with_owner:.1f}/100",
            "is_sleeping": self.is_sleeping,
            "is_sick": self.is_sick,
            "sickness": self.sickness_type if self.is_sick else "å¥åº·",
            "personality": [f"{t.value}({s:.1f})" for t, s in self.personality_traits.items()],
            "skills": self.skills,
            "color": self.color,
            "size": self.size
        }
        
        # æ·»åŠ ç¡çœ çŠ¶æ€ä¿¡æ¯
        if self.is_sleeping:
            sleep_info = self.get_sleep_status()
            status.update(sleep_info)
        
        return status
    
    def get_sleep_status(self):
        """è·å–ç¡çœ çŠ¶æ€ä¿¡æ¯"""
        if not self.is_sleeping:
            return {}
        
        # è®¡ç®—å·²ç¡çœ æ—¶é•¿
        sleep_duration = 0
        if self.sleep_start_time:
            sleep_duration = (time.time() - self.sleep_start_time) / 3600  # è½¬æ¢ä¸ºå°æ—¶
        
        # è®¡ç®—é¢„è®¡é†’æ¥æ—¶é—´
        energy_needed = 100 - self.energy
        hours_needed = energy_needed / 15.0  # æ¯å°æ—¶æ¢å¤15ç‚¹èƒ½é‡
        hours_needed = max(0.1, hours_needed)  # è‡³å°‘éœ€è¦0.1å°æ—¶
        
        # æ ¹æ®æ€§æ ¼è°ƒæ•´
        if PetPersonality.LAZY in self.personality_traits:
            hours_needed *= 1.5
        
        estimated_wake_time = time.time() + (hours_needed * 3600)
        wake_time_str = time.strftime("%H:%M", time.localtime(estimated_wake_time))
        
        # è®¡ç®—ç¡çœ è¿›åº¦
        energy_progress = min(100, (self.energy / 100) * 100)
        
        return {
            "sleep_duration": f"{sleep_duration:.1f}å°æ—¶",
            "estimated_wake_time": wake_time_str,
            "sleep_progress": f"{energy_progress:.1f}%",
            "sleep_quality_prediction": "é¢„è®¡è‰¯å¥½" if hours_needed >= 0.5 else "é¢„è®¡æ™®é€š"
        }
    
    def get_needs_summary(self):
        """è·å–éœ€æ±‚æ‘˜è¦ï¼ˆç”¨äºUIæ˜¾ç¤ºï¼‰"""
        needs = []
        
        if self.hunger > 70:
            needs.append(("é¥¥é¥¿", "é«˜"))
        elif self.hunger > 40:
            needs.append(("é¥¥é¥¿", "ä¸­"))
        
        if self.energy < 30:
            needs.append(("ç–²åŠ³", "é«˜"))
        elif self.energy < 60:
            needs.append(("ç–²åŠ³", "ä¸­"))
        
        if self.hygiene < 30:
            needs.append(("æ¸…æ´", "é«˜"))
        elif self.hygiene < 60:
            needs.append(("æ¸…æ´", "ä¸­"))
        
        if self.happiness < 30:
            needs.append(("ä¸å¼€å¿ƒ", "é«˜"))
        elif self.happiness < 60:
            needs.append(("ä¸å¼€å¿ƒ", "ä¸­"))
        
        if self.health < 50:
            needs.append(("å¥åº·", "è­¦å‘Š"))
        
        return needs
    
    def save_to_file(self, filename):
        """ä¿å­˜å® ç‰©æ•°æ®åˆ°æ–‡ä»¶"""
        data = {
            "name": self.name,
            "species": self.species,
            "birthday": self.birthday.isoformat(),
            "age_in_days": self.age_in_days,
            "state": self.state.value,
            "mood": self.mood.value,
            "health": self.health,
            "hunger": self.hunger,
            "energy": self.energy,
            "hygiene": self.hygiene,
            "happiness": self.happiness,
            "weight": self.weight,
            "personality_traits": {k.value: v for k, v in self.personality_traits.items()},
            "experience": self.experience,
            "level": self.level,
            "skills": self.skills,
            "memories": self.memories,
            "relationship_with_owner": self.relationship_with_owner,
            "routine_preferences": dict(self.routine_preferences),
            "color": self.color,
            "size": self.size,
            "is_sleeping": self.is_sleeping,
            "is_sick": self.is_sick,
            "sickness_type": self.sickness_type,
            "last_update_time": self.last_update_time,
            "accessories": self.accessories,
            "needs_update": self.needs_update,
            "emotional_system": self.emotional_system.save_emotional_data()
        }
        
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        
        # ä¿å­˜å¼ºåŒ–å­¦ä¹ æ•°æ®ï¼ˆå¦‚æœæœ‰ï¼‰
        if hasattr(self, 'reinforcement_learning'):
            rl_filename = filename.replace('.json', '_rl.json')
            self.reinforcement_learning.save_learning_data(rl_filename)
        
        return True
    
    @classmethod
    def load_from_file(cls, filename):
        """ä»æ–‡ä»¶åŠ è½½å® ç‰©æ•°æ®"""
        with open(filename, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        # åˆ›å»ºæ–°å® ç‰©
        pet = cls(name=data["name"], species=data["species"])
        pet.birthday = datetime.fromisoformat(data["birthday"])
        pet.age_in_days = data["age_in_days"]
        
        # æ¢å¤çŠ¶æ€
        pet.state = PetState(data["state"])
        pet.mood = PetMood(data["mood"])
        pet.health = data["health"]
        pet.hunger = data["hunger"]
        pet.energy = data["energy"]
        pet.hygiene = data["hygiene"]
        pet.happiness = data["happiness"]
        pet.weight = data["weight"]
        
        # æ¢å¤æ€§æ ¼
        pet.personality_traits = {
            PetPersonality(k): v for k, v in data["personality_traits"].items()
        }
        
        # æ¢å¤æˆé•¿æ•°æ®
        pet.experience = data["experience"]
        pet.level = data["level"]
        pet.skills = data["skills"]
        pet.memories = data["memories"]
        pet.relationship_with_owner = data["relationship_with_owner"]
        
        # æ¢å¤åå¥½
        pet.routine_preferences = defaultdict(int, data.get("routine_preferences", {}))
        
        # æ¢å¤å¤–è§‚
        pet.color = data["color"]
        pet.size = data["size"]
        pet.accessories = data.get("accessories", [])
        
        # æ¢å¤ç‰¹æ®ŠçŠ¶æ€
        pet.is_sleeping = data["is_sleeping"]
        pet.is_sick = data["is_sick"]
        pet.sickness_type = data["sickness_type"]
        
        # æ¢å¤æ—¶é—´
        pet.last_update_time = data["last_update_time"]
        pet.needs_update = data.get("needs_update", True)
        
        # æ¢å¤æƒ…æ„Ÿç³»ç»Ÿ
        if "emotional_system" in data:
            pet.emotional_system.load_emotional_data(data["emotional_system"])
        
        # åŠ è½½å¼ºåŒ–å­¦ä¹ æ•°æ®ï¼ˆå¦‚æœæœ‰ï¼‰
        if hasattr(pet, 'reinforcement_learning'):
            rl_filename = filename.replace('.json', '_rl.json')
            if os.path.exists(rl_filename):
                pet.reinforcement_learning.load_learning_data(rl_filename)
        
        # ç«‹å³æ›´æ–°çŠ¶æ€
        pet.update()
        
        print(f"âœ¨ å·²åŠ è½½å® ç‰©: {pet.name} (ç­‰çº§ {pet.level})")
        return pet


class IntelligentPet(VirtualPet): # æ ¸å¿ƒåŠŸèƒ½ï¼šè®©å® ç‰©èƒ½å¤Ÿè‡ªå‘è¡Œä¸ºå’Œä»äº¤äº’ä¸­å­¦ä¹ 
    """æ™ºèƒ½å® ç‰©ç±» - ç¬¬äºŒé˜¶æ®µå¼ºåŒ–å­¦ä¹ æ™ºèƒ½ä½“"""
    def __init__(self, name="æœªå‘½å", species="æœªçŸ¥"):
        super().__init__(name, species)
        
        # æ™ºèƒ½ä½“ç›¸å…³å±æ€§
        self.decision_system = DecisionSystem(self)
        self.behavior_system = BehaviorSystem(self)
        self.learning_system = LearningSystem(self)
        
        # ç¬¬äºŒé˜¶æ®µï¼šå¼ºåŒ–å­¦ä¹ ç³»ç»Ÿ
        self.reinforcement_learning = ReinforcementLearningSystem(self)
        
        # ç¬¬äºŒé˜¶æ®µï¼šè¡Œä¸ºæ ‘ç³»ç»Ÿ
        self.behavior_tree = BehaviorTreeBuilder.build_pet_behavior_tree()
        
        # ä¸»åŠ¨è¡Œä¸ºç›¸å…³
        self.last_spontaneous_action = time.time()
        self.spontaneous_action_cooldown = 30  # è‡ªå‘è¡Œä¸ºå†·å´æ—¶é—´ï¼ˆç§’ï¼‰
        
        # ç”¨æˆ·åå¥½è®°å½•
        self.user_preferences = defaultdict(Counter)
        
        print(f"ğŸ§  æ™ºèƒ½å® ç‰© {name} å·²æ¿€æ´»ï¼")
        print(f"ğŸš€ å¼ºåŒ–å­¦ä¹ ç³»ç»Ÿå·²å¯åŠ¨ï¼")
        print(f"ğŸŒ³ è¡Œä¸ºæ ‘ç³»ç»Ÿå·²åˆå§‹åŒ–ï¼")
    
    def update(self, current_time=None):
        """æ›´æ–°å® ç‰©çŠ¶æ€ï¼ŒåŒ…æ‹¬æ™ºèƒ½ä½“å†³ç­–"""
        super().update(current_time)
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦æ‰§è¡Œè‡ªå‘è¡Œä¸º
        if current_time is None:
            current_time = time.time()
        
        if current_time - self.last_spontaneous_action > self.spontaneous_action_cooldown:
            self.execute_spontaneous_action()
            self.last_spontaneous_action = current_time
    
    def execute_spontaneous_action(self):
        """æ‰§è¡Œè‡ªå‘è¡Œä¸ºï¼ˆä½¿ç”¨å¼ºåŒ–å­¦ä¹ å’Œè¡Œä¸ºæ ‘ï¼‰"""
        # ç¬¬äºŒé˜¶æ®µï¼šä¼˜å…ˆä½¿ç”¨å¼ºåŒ–å­¦ä¹ å†³ç­–
        state_before = self.reinforcement_learning.get_discrete_state()
        action = self.reinforcement_learning.choose_action(state_before)
        
        if action:
            # æ‰§è¡Œè¡Œä¸º
            result = self._execute_action(action)
            
            # è¯„ä¼°æ‰§è¡Œåçš„çŠ¶æ€
            state_after = self.reinforcement_learning.get_discrete_state()
            
            # è®¡ç®—å¥–åŠ±
            reward = self.reinforcement_learning.calculate_reward(
                dict(state_before), action, dict(state_after)
            )
            
            # å¼ºåŒ–å­¦ä¹ 
            self.reinforcement_learning.learn(state_before, action, reward, state_after, False)
            
            # è®°å½•è¡Œä¸ºç»“æœ
            self.learning_system.record_behavior(action, result, {})
            
            return result
        else:
            # å¤‡ç”¨ï¼šä½¿ç”¨è¡Œä¸ºæ ‘
            return self.execute_behavior_tree_action()
    
    def execute_behavior_tree_action(self):
        """æ‰§è¡Œè¡Œä¸ºæ ‘åŠ¨ä½œ"""
        status = self.behavior_tree.execute(self)
        return f"è¡Œä¸ºæ ‘æ‰§è¡ŒçŠ¶æ€: {status}"
    
    def _execute_action(self, action):
        """æ‰§è¡Œå…·ä½“è¡Œä¸º"""
        if action == "feed":
            return self.feed("æ™®é€šé£Ÿç‰©")
        elif action == "play":
            return self.play("æ™®é€šæ¸¸æˆ")
        elif action == "sleep":
            return self.sleep()
        elif action == "clean":
            return self.clean()
        elif action == "train":
            return self.train("intelligence")
        elif action == "explore":
            return self._explore()
        elif action == "rest":
            return self._rest()
        else:
            return f"æ‰§è¡Œè¡Œä¸º: {action}"
    
    def _explore(self):
        """æ¢ç´¢ç¯å¢ƒ"""
        if self.energy < 15:
            return f"{self.name}ï¼š'æˆ‘å¤ªç´¯äº†ï¼Œä¸æƒ³åŠ¨'"
        
        energy_cost = 15
        happiness_gain = 10
        intelligence_gain = 0.5
        
        self.energy = max(0, self.energy - energy_cost)
        self.happiness = min(100, self.happiness + happiness_gain)
        self.skills["intelligence"] += intelligence_gain
        
        # æ£€æŸ¥ç²¾åŠ›å€¼ï¼Œå¦‚æœå°äº50%ï¼Œåˆ™å»ç¡è§‰
        sleep_result = self._check_energy_and_sleep()
        if sleep_result:
            return f"{self.name}æ­£åœ¨å¥½å¥‡åœ°æ¢ç´¢å‘¨å›´ç¯å¢ƒ\n{sleep_result}"
        
        return f"{self.name}æ­£åœ¨å¥½å¥‡åœ°æ¢ç´¢å‘¨å›´ç¯å¢ƒ"
    
    def _check_energy_and_sleep(self):
        """æ£€æŸ¥ç²¾åŠ›å€¼ï¼Œå¦‚æœå°äº50%ï¼Œåˆ™å»ç¡è§‰"""
        if not self.is_sleeping and self.energy < 50:
            return self.sleep()
        return ""
    
    def _rest(self):
        """ä¼‘æ¯æ¢å¤"""
        energy_gain = 20
        health_gain = 5
        
        self.energy = min(100, self.energy + energy_gain)
        self.health = min(100, self.health + health_gain)
        
        # æ£€æŸ¥ç²¾åŠ›å€¼ï¼Œå¦‚æœå°äº50%ï¼Œåˆ™å»ç¡è§‰
        sleep_result = self._check_energy_and_sleep()
        if sleep_result:
            return f"{self.name}æ­£åœ¨ä¼‘æ¯æ¢å¤ç²¾åŠ›\n{sleep_result}"
        
        return f"{self.name}æ­£åœ¨ä¼‘æ¯æ¢å¤ç²¾åŠ›"
    
    def interact_with_user(self, interaction_type, **kwargs):
        """ä¸ç”¨æˆ·äº¤äº’å¹¶å­¦ä¹ """
        # æ‰§è¡Œä¼ ç»Ÿäº¤äº’
        if interaction_type == "feed":
            food_type = kwargs.get("food_type", "æ™®é€šé£Ÿç‰©")
            result = self.feed(food_type)
        elif interaction_type == "play":
            game_type = kwargs.get("game_type", "æ™®é€šæ¸¸æˆ")
            result = self.play(game_type)
        elif interaction_type == "sleep":
            result = self.sleep()
        elif interaction_type == "wake_up":
            result = self.wake_up()
        elif interaction_type == "clean":
            clean_type = kwargs.get("clean_type", "æ¯›å‘æ¸…ç†")
            result = self.clean(clean_type)
        elif interaction_type == "train":
            skill_type = kwargs.get("skill_type", "intelligence")
            result = self.train(skill_type)
        elif interaction_type == "change_color":
            new_color = kwargs.get("new_color", "ç™½è‰²")
            result = self.change_color(new_color)
        else:
            result = "æœªçŸ¥äº¤äº’ç±»å‹"
        
        # è®°å½•ç”¨æˆ·äº¤äº’åå¥½
        self.learning_system.record_user_interaction(interaction_type, kwargs)
        
        # å­¦ä¹ ç³»ç»Ÿæ›´æ–°
        self.learning_system.learn_from_interaction(interaction_type, result)
        
        # ç¬¬äºŒé˜¶æ®µï¼šå¼ºåŒ–å­¦ä¹ æ›´æ–°
        state_before = self.reinforcement_learning.get_discrete_state()
        # å°†ç”¨æˆ·äº¤äº’æ˜ å°„åˆ°å¼ºåŒ–å­¦ä¹ åŠ¨ä½œ
        rl_action = self._map_interaction_to_rl_action(interaction_type)
        if rl_action:
            state_after = self.reinforcement_learning.get_discrete_state()
            reward = self.reinforcement_learning.calculate_reward(
                dict(state_before), rl_action, dict(state_after)
            )
            self.reinforcement_learning.learn(state_before, rl_action, reward, state_after, False)
        
        return result
    
    def _map_interaction_to_rl_action(self, interaction_type):
        """å°†ç”¨æˆ·äº¤äº’æ˜ å°„åˆ°å¼ºåŒ–å­¦ä¹ åŠ¨ä½œ"""
        mapping = {
            "feed": "feed",
            "play": "play",
            "sleep": "sleep",
            "wake_up": "explore",  # é†’æ¥åæ¢ç´¢
            "clean": "clean",
            "train": "train"
        }
        return mapping.get(interaction_type)
    
    def get_intelligent_status(self):
        """è·å–æ™ºèƒ½ä½“çŠ¶æ€"""
        base_status = self.get_status()
        
        # æ·»åŠ æ™ºèƒ½ä½“ç›¸å…³ä¿¡æ¯
        intelligent_status = {
            "decision_confidence": self.decision_system.get_confidence(),
            "predicted_needs": self.decision_system.predict_needs(),
            "learned_preferences": dict(self.learning_system.get_preferences()),
            "spontaneous_action_rate": self.behavior_system.get_action_rate(),
            "next_action_prediction": self.decision_system.predict_next_action(),
            # ç¬¬äºŒé˜¶æ®µï¼šå¼ºåŒ–å­¦ä¹ ä¿¡æ¯
            "reinforcement_learning": self.reinforcement_learning.get_learning_stats()
        }
        
        base_status.update(intelligent_status)
        return base_status
    
    def get_learning_progress(self):
        """è·å–å­¦ä¹ è¿›åº¦"""
        return {
            "exploration_rate": self.reinforcement_learning.exploration_rate,
            "average_reward": self.reinforcement_learning.average_reward,
            "learning_steps": self.reinforcement_learning.learning_steps,
            "q_table_size": sum(len(v) for v in self.reinforcement_learning.q_table.values())
        }
    
    def beg_for_food(self):
        """å‘ä¸»äººä¹è®¨é£Ÿç‰©"""
        self.happiness += 5  # ä¹è®¨è¡Œä¸ºå¢åŠ ä¸€ç‚¹å¿«ä¹
        return f"{self.name}ï¼š'æˆ‘é¥¿äº†ï¼Œæƒ³åƒä¸œè¥¿ï¼'"
    
    def groom(self):
        """è‡ªæˆ‘æ¸…æ´"""
        hygiene_gain = 15
        self.hygiene = min(100, self.hygiene + hygiene_gain)
        self.happiness += 5
        return f"{self.name}æ­£åœ¨èˆ”æ¯›æ¸…æ´è‡ªå·±"
    
    def spontaneous_play(self):
        """è‡ªå‘ç©è€"""
        if self.energy < 20:
            return f"{self.name}ï¼š'æˆ‘å¤ªç´¯äº†ï¼Œæƒ³ä¼‘æ¯'"
        
        energy_cost = 10
        happiness_gain = 15
        
        self.energy = max(0, self.energy - energy_cost)
        self.happiness = min(100, self.happiness + happiness_gain)
        
        return f"{self.name}æ­£åœ¨å¼€å¿ƒåœ°ç©è€"


class DecisionSystem:
    """å†³ç­–ç³»ç»Ÿ - åŸºäºè§„åˆ™çš„å†³ç­–é€»è¾‘"""
    def __init__(self, pet):
        self.pet = pet
        self.decision_history = []
        self.confidence_level = 0.5
    
    def evaluate_state(self):
        """è¯„ä¼°å½“å‰çŠ¶æ€"""
        needs = self.pet.get_needs_summary()
        
        # ä¼˜å…ˆçº§è¯„ä¼°
        priority_needs = {
            "health": 0,
            "hunger": 0,
            "energy": 0,
            "hygiene": 0,
            "happiness": 0
        }
        
        # å¥åº·ä¼˜å…ˆçº§
        if self.pet.health < 30:
            priority_needs["health"] = 5
        elif self.pet.health < 60:
            priority_needs["health"] = 3
        
        # é¥¥é¥¿ä¼˜å…ˆçº§
        if self.pet.hunger > 80:
            priority_needs["hunger"] = 4
        elif self.pet.hunger > 60:
            priority_needs["hunger"] = 2
        
        # ç²¾åŠ›ä¼˜å…ˆçº§
        if self.pet.energy < 20:
            priority_needs["energy"] = 4
        elif self.pet.energy < 40:
            priority_needs["energy"] = 2
        
        # æ¸…æ´ä¼˜å…ˆçº§
        if self.pet.hygiene < 20:
            priority_needs["hygiene"] = 3
        elif self.pet.hygiene < 40:
            priority_needs["hygiene"] = 1
        
        # å¿«ä¹ä¼˜å…ˆçº§
        if self.pet.happiness < 20:
            priority_needs["happiness"] = 3
        elif self.pet.happiness < 40:
            priority_needs["happiness"] = 1
        
        # ç‰¹æ®ŠçŠ¶æ€
        if self.pet.is_sick:
            priority_needs["health"] = max(priority_needs["health"], 5)
        
        if self.pet.is_sleeping:
            priority_needs["energy"] = 0  # ç¡è§‰æ—¶ä¸è€ƒè™‘ç²¾åŠ›
        
        return {
            "needs": needs,
            "priority_needs": priority_needs,
            "current_state": self.pet.state.value,
            "mood": self.pet.mood.value,
            "is_sleeping": self.pet.is_sleeping,
            "is_sick": self.pet.is_sick
        }
    
    def make_decision(self, state_evaluation):
        """åŸºäºçŠ¶æ€åšå‡ºå†³ç­–"""
        if self.pet.is_sleeping:
            # æ£€æŸ¥æ˜¯å¦éœ€è¦é†’æ¥
            if self.pet.energy > 90:
                return "wake_up"
            return None
        
        # åŸºäºä¼˜å…ˆçº§éœ€æ±‚åšå‡ºå†³ç­–
        priority_needs = state_evaluation["priority_needs"]
        highest_priority = max(priority_needs.items(), key=lambda x: x[1])
        
        if highest_priority[1] == 0:
            # æ‰€æœ‰éœ€æ±‚éƒ½å¾—åˆ°æ»¡è¶³ï¼Œéšæœºé€‰æ‹©ä¸€ä¸ªæ„‰æ‚¦è¡Œä¸º
            return random.choice(["play", "explore"])
        
        # æ ¹æ®æœ€é«˜ä¼˜å…ˆçº§éœ€æ±‚é€‰æ‹©è¡Œä¸º
        if highest_priority[0] == "health":
            if self.pet.is_sick:
                return "rest"
            else:
                return "rest"
        elif highest_priority[0] == "hunger":
            return "beg_for_food"
        elif highest_priority[0] == "energy":
            return "sleep"
        elif highest_priority[0] == "hygiene":
            return "groom"
        elif highest_priority[0] == "happiness":
            return "play"
        
        return "explore"
    
    def get_confidence(self):
        """è·å–å†³ç­–ä¿¡å¿ƒ"""
        # åŸºäºçŠ¶æ€è¯„ä¼°çš„ç¡®å®šæ€§è®¡ç®—ä¿¡å¿ƒ
        return min(1.0, self.confidence_level + len(self.decision_history) * 0.01)
    
    def predict_needs(self):
        """é¢„æµ‹æœªæ¥éœ€æ±‚"""
        # åŸºäºå½“å‰çŠ¶æ€å’Œå†å²æ¨¡å¼é¢„æµ‹éœ€æ±‚
        predictions = []
        
        if self.pet.hunger > 60:
            predictions.append("hunger")
        if self.pet.energy < 40:
            predictions.append("energy")
        if self.pet.hygiene < 40:
            predictions.append("hygiene")
        
        return predictions
    
    def predict_next_action(self):
        """é¢„æµ‹ä¸‹ä¸€ä¸ªè¡Œä¸º"""
        state_evaluation = self.evaluate_state()
        return self.make_decision(state_evaluation)


class BehaviorSystem:
    """è¡Œä¸ºç³»ç»Ÿ - æ‰§è¡Œè‡ªä¸»è¡Œä¸º"""
    def __init__(self, pet):
        self.pet = pet
        self.action_history = []
        self.action_success_rate = defaultdict(float)
    
    def execute_action(self, action):
        """æ‰§è¡Œé€‰å®šçš„è¡Œä¸º"""
        if action is None:
            return "æ— è¡Œä¸ºæ‰§è¡Œ"
        
        # è®°å½•è¡Œä¸º
        self.action_history.append((action, time.time()))
        
        # æ‰§è¡Œè¡Œä¸º
        if action == "wake_up":
            return self.pet.wake_up()
        elif action == "sleep":
            return self.pet.sleep()
        elif action == "beg_for_food":
            return self._beg_for_food()
        elif action == "groom":
            return self._groom()
        elif action == "play":
            return self._spontaneous_play()
        elif action == "rest":
            return self._rest()
        elif action == "explore":
            return self._explore()
        
        return f"æ‰§è¡Œè¡Œä¸º: {action}"
    
    def _beg_for_food(self):
        """å‘ä¸»äººä¹è®¨é£Ÿç‰©"""
        self.pet.happiness += 5  # ä¹è®¨è¡Œä¸ºå¢åŠ ä¸€ç‚¹å¿«ä¹
        return f"{self.pet.name}ï¼š'æˆ‘é¥¿äº†ï¼Œæƒ³åƒä¸œè¥¿ï¼'"
    
    def _groom(self):
        """è‡ªæˆ‘æ¸…æ´"""
        hygiene_gain = 15
        self.pet.hygiene = min(100, self.pet.hygiene + hygiene_gain)
        self.pet.happiness += 5
        return f"{self.pet.name}æ­£åœ¨èˆ”æ¯›æ¸…æ´è‡ªå·±"
    
    def _spontaneous_play(self):
        """è‡ªå‘ç©è€"""
        if self.pet.energy < 20:
            return f"{self.pet.name}ï¼š'æˆ‘å¤ªç´¯äº†ï¼Œæƒ³ä¼‘æ¯'"
        
        energy_cost = 10
        happiness_gain = 15
        
        self.pet.energy = max(0, self.pet.energy - energy_cost)
        self.pet.happiness = min(100, self.pet.happiness + happiness_gain)
        
        return f"{self.pet.name}æ­£åœ¨å¼€å¿ƒåœ°ç©è€"
    
    def _rest(self):
        """ä¼‘æ¯æ¢å¤"""
        energy_gain = 20
        health_gain = 5
        
        self.pet.energy = min(100, self.pet.energy + energy_gain)
        self.pet.health = min(100, self.pet.health + health_gain)
        
        return f"{self.pet.name}æ­£åœ¨ä¼‘æ¯æ¢å¤ç²¾åŠ›"
    
    def _explore(self):
        """æ¢ç´¢ç¯å¢ƒ"""
        if self.pet.energy < 15:
            return f"{self.pet.name}ï¼š'æˆ‘å¤ªç´¯äº†ï¼Œä¸æƒ³åŠ¨'"
        
        energy_cost = 15
        happiness_gain = 10
        intelligence_gain = 0.5
        
        self.pet.energy = max(0, self.pet.energy - energy_cost)
        self.pet.happiness = min(100, self.pet.happiness + happiness_gain)
        self.pet.skills["intelligence"] += intelligence_gain
        
        return f"{self.pet.name}æ­£åœ¨å¥½å¥‡åœ°æ¢ç´¢å‘¨å›´ç¯å¢ƒ"
    
    def get_action_rate(self):
        """è·å–è¡Œä¸ºé¢‘ç‡"""
        # è®¡ç®—æœ€è¿‘è¡Œä¸ºé¢‘ç‡
        recent_actions = [a for a, t in self.action_history if time.time() - t < 3600]
        return len(recent_actions) / 60.0  # æ¯å°æ—¶è¡Œä¸ºæ•°


class LearningSystem:
    """å­¦ä¹ ç³»ç»Ÿ - è®°å½•ç”¨æˆ·åå¥½å’Œè¡Œä¸ºæ¨¡å¼"""
    def __init__(self, pet):
        self.pet = pet
        self.interaction_history = []
        self.behavior_effects = defaultdict(list)
        self.time_based_preferences = defaultdict(Counter)
    
    def record_user_interaction(self, interaction_type, kwargs):
        """è®°å½•ç”¨æˆ·äº¤äº’"""
        timestamp = time.time()
        hour = datetime.fromtimestamp(timestamp).hour
        
        self.interaction_history.append({
            "type": interaction_type,
            "kwargs": kwargs,
            "timestamp": timestamp,
            "hour": hour
        })
        
        # è®°å½•æ—¶é—´åå¥½
        self.time_based_preferences[hour][interaction_type] += 1
        
        # è®°å½•å…·ä½“åå¥½
        if interaction_type == "feed" and "food_type" in kwargs:
            self.pet.user_preferences["food"][kwargs["food_type"]] += 1
        elif interaction_type == "play" and "game_type" in kwargs:
            self.pet.user_preferences["game"][kwargs["game_type"]] += 1
        elif interaction_type == "train" and "skill_type" in kwargs:
            self.pet.user_preferences["skill"][kwargs["skill_type"]] += 1
    
    def record_behavior(self, action, result, state_evaluation):
        """è®°å½•è¡Œä¸ºç»“æœ"""
        self.behavior_effects[action].append({
            "result": result,
            "state_before": state_evaluation,
            "timestamp": time.time()
        })
    
    def learn_from_interaction(self, interaction_type, result):
        """ä»äº¤äº’ä¸­å­¦ä¹ """
        # ç®€å•çš„å¼ºåŒ–å­¦ä¹  - åŸºäºç»“æœè°ƒæ•´åå¥½
        if "æˆåŠŸ" in result or "å¼€å¿ƒ" in result:
            # æ­£é¢ç»“æœï¼Œå¢åŠ è¯¥è¡Œä¸ºåå¥½
            self.pet.routine_preferences[interaction_type] += 2
        elif "æ— æ³•" in result or "å¤ªç´¯" in result:
            # è´Ÿé¢ç»“æœï¼Œå‡å°‘è¯¥è¡Œä¸ºåå¥½
            if self.pet.routine_preferences[interaction_type] > 0:
                self.pet.routine_preferences[interaction_type] -= 1
    
    def get_preferences(self):
        """è·å–å­¦ä¹ åˆ°çš„åå¥½"""
        preferences = {}
        
        # é£Ÿç‰©åå¥½
        if self.pet.user_preferences["food"]:
            preferences["food"] = dict(self.pet.user_preferences["food"])
        
        # æ¸¸æˆåå¥½
        if self.pet.user_preferences["game"]:
            preferences["game"] = dict(self.pet.user_preferences["game"])
        
        # æŠ€èƒ½è®­ç»ƒåå¥½
        if self.pet.user_preferences["skill"]:
            preferences["skill"] = dict(self.pet.user_preferences["skill"])
        
        # æ—¶é—´åå¥½
        time_preferences = {}
        for hour, counts in self.time_based_preferences.items():
            if counts:
                time_preferences[hour] = dict(counts)
        
        if time_preferences:
            preferences["time"] = time_preferences
        
        return preferences
    
    def predict_user_action(self, hour=None):
        """é¢„æµ‹ç”¨æˆ·å¯èƒ½çš„è¡Œä¸º"""
        if hour is None:
            hour = datetime.now().hour
        
        # åŸºäºæ—¶é—´çš„è¡Œä¸ºé¢„æµ‹
        if hour in self.time_based_preferences:
            most_common = self.time_based_preferences[hour].most_common(1)
            if most_common:
                return most_common[0][0]
        
        # åŸºäºå†å²é¢‘ç‡çš„é¢„æµ‹
        if self.interaction_history:
            recent_interactions = [i["type"] for i in self.interaction_history[-10:]]
            if recent_interactions:
                return Counter(recent_interactions).most_common(1)[0][0]
        
        return None


class ReinforcementLearningSystem:
    """å¼ºåŒ–å­¦ä¹ ç³»ç»Ÿ - åŸºäºæ”¹è¿›Q-learningçš„æ™ºèƒ½å†³ç­–"""
    def __init__(self, pet, learning_rate=0.1, discount_factor=0.9, exploration_rate=1.0, exploration_decay=0.995, min_exploration=0.1):
        self.pet = pet
        self.learning_rate = learning_rate
        self.discount_factor = discount_factor
        self.exploration_rate = exploration_rate
        self.exploration_decay = exploration_decay
        self.min_exploration = min_exploration
        
        # Q-table å­˜å‚¨ï¼ˆåŒQå­¦ä¹ ï¼‰
        self.q_table_1 = defaultdict(lambda: defaultdict(float))
        self.q_table_2 = defaultdict(lambda: defaultdict(float))
        
        # ä¼˜å…ˆç»éªŒå›æ”¾
        self.replay_buffer = []
        self.buffer_size = 2000
        self.priorities = []
        
        # çŠ¶æ€ç¦»æ•£åŒ–å‚æ•°ï¼ˆæ›´ç²¾ç»†çš„åˆ’åˆ†ï¼‰
        self.state_bins = {
            "health": [0, 20, 40, 60, 80, 100],
            "hunger": [0, 20, 40, 60, 80, 100],
            "energy": [0, 20, 40, 60, 80, 100],
            "hygiene": [0, 20, 40, 60, 80, 100],
            "happiness": [0, 20, 40, 60, 80, 100],
            "age": [0, 10, 30, 90, 365]
        }
        
        # åŠ¨ä½œç©ºé—´
        self.actions = ["feed", "play", "sleep", "clean", "train", "explore", "rest"]
        
        # å­¦ä¹ ç»Ÿè®¡
        self.learning_steps = 0
        self.total_reward = 0
        self.average_reward = 0
        self.episode_rewards = []
        
        # å†…åœ¨åŠ¨æœºç³»ç»Ÿ
        self.visitation_counts = defaultdict(int)
        self.curiosity_bonus = 0.1
        
        # ç›®æ ‡æƒé‡ç³»ç»Ÿ
        self.goal_weights = {
            "health": 1.0,
            "hunger": 1.0,
            "energy": 0.8,
            "hygiene": 0.6,
            "happiness": 1.2,
            "growth": 0.5
        }
        
        # å†å²çŠ¶æ€è®°å½•
        self.state_history = []
        self.action_history = []
        self.history_length = 5
        
        print("ğŸ§  å¼ºåŒ–å­¦ä¹ ç³»ç»Ÿå·²åˆå§‹åŒ–ï¼")
    
    def get_discrete_state(self):
        """è·å–ç¦»æ•£åŒ–çš„çŠ¶æ€ï¼ˆåŒ…å«å†å²ä¿¡æ¯ï¼‰"""
        state = {
            "health": self._discretize_value(self.pet.health, self.state_bins["health"]),
            "hunger": self._discretize_value(self.pet.hunger, self.state_bins["hunger"]),
            "energy": self._discretize_value(self.pet.energy, self.state_bins["energy"]),
            "hygiene": self._discretize_value(self.pet.hygiene, self.state_bins["hygiene"]),
            "happiness": self._discretize_value(self.pet.happiness, self.state_bins["happiness"]),
            "age": self._discretize_value(self.pet.age_in_days, self.state_bins["age"]),
            "is_sleeping": int(self.pet.is_sleeping),
            "is_sick": int(self.pet.is_sick),
            "mood": self._get_mood_value()
        }
        
        # æ·»åŠ å†å²è¶‹åŠ¿ä¿¡æ¯
        if len(self.state_history) > 0:
            state["health_trend"] = self._get_trend(self.pet.health, "health")
            state["hunger_trend"] = self._get_trend(self.pet.hunger, "hunger")
            state["energy_trend"] = self._get_trend(self.pet.energy, "energy")
        else:
            state["health_trend"] = 0
            state["hunger_trend"] = 0
            state["energy_trend"] = 0
        
        # æ›´æ–°å†å²
        self.state_history.append(state.copy())
        if len(self.state_history) > self.history_length:
            self.state_history.pop(0)
        
        return tuple(sorted(state.items()))
    
    def _get_mood_value(self):
        """å°†å¿ƒæƒ…è½¬æ¢ä¸ºæ•°å€¼"""
        mood_values = {
            "ç‹‚å–œ": 6,
            "å¿«ä¹": 5,
            "æ»¡è¶³": 4,
            "ä¸€èˆ¬": 3,
            "æ‚²ä¼¤": 2,
            "æŠ‘éƒ": 1,
            "ç”Ÿæ°”": 0
        }
        return mood_values.get(self.pet.mood.value, 3)
    
    def _get_trend(self, current_value, attribute):
        """è·å–å±æ€§å˜åŒ–è¶‹åŠ¿"""
        if len(self.state_history) == 0:
            return 0
        
        previous_state = self.state_history[-1]
        previous_value = getattr(self.pet, attribute)
        
        if current_value > previous_value:
            return 1  # ä¸Šå‡
        elif current_value < previous_value:
            return -1  # ä¸‹é™
        else:
            return 0  # ä¸å˜
    
    def _discretize_value(self, value, bins):
        """å°†è¿ç»­å€¼ç¦»æ•£åŒ–"""
        for i, bin_threshold in enumerate(bins):
            if value <= bin_threshold:
                return i
        return len(bins) - 1
    
    def choose_action(self, state):
        """åŸºäºæ”¹è¿›çš„Îµ-è´ªå©ªç­–ç•¥é€‰æ‹©åŠ¨ä½œï¼ˆåŒQå­¦ä¹ ï¼‰"""
        # æ¢ç´¢
        if random.uniform(0, 1) < self.exploration_rate:
            action = random.choice(self.actions)
            # è®°å½•æ¢ç´¢åŠ¨ä½œ
            self.visitation_counts[(state, action)] += 1
            return action
        # åˆ©ç”¨ï¼ˆåŒQå­¦ä¹ ï¼‰
        else:
            # åˆå¹¶ä¸¤ä¸ªQè¡¨
            combined_q = defaultdict(float)
            for action in self.actions:
                q1 = self.q_table_1[state].get(action, 0)
                q2 = self.q_table_2[state].get(action, 0)
                combined_q[action] = (q1 + q2) / 2
            
            if combined_q:
                action = max(combined_q, key=combined_q.get)
                self.visitation_counts[(state, action)] += 1
                return action
            else:
                action = random.choice(self.actions)
                self.visitation_counts[(state, action)] += 1
                return action
    
    def calculate_reward(self, state_before, action, state_after):
        """è®¡ç®—æ”¹è¿›çš„å¥–åŠ±å‡½æ•°ï¼ˆåŒ…å«å½¢çŠ¶å¥–åŠ±å’Œå†…åœ¨åŠ¨æœºï¼‰"""
        reward = 0
        
        # åŸºç¡€å¥–åŠ±ï¼šç»´æŒè‰¯å¥½çŠ¶æ€ï¼ˆä½¿ç”¨ç›®æ ‡æƒé‡ï¼‰
        if state_after["health"] >= 4:
            reward += 1.5 * self.goal_weights["health"]
        elif state_after["health"] >= 3:
            reward += 1.0 * self.goal_weights["health"]
        
        if state_after["hunger"] <= 1:
            reward += 1.5 * self.goal_weights["hunger"]
        elif state_after["hunger"] <= 2:
            reward += 1.0 * self.goal_weights["hunger"]
        
        if state_after["energy"] >= 4:
            reward += 1.0 * self.goal_weights["energy"]
        elif state_after["energy"] >= 3:
            reward += 0.5 * self.goal_weights["energy"]
        
        if state_after["hygiene"] >= 4:
            reward += 0.8 * self.goal_weights["hygiene"]
        elif state_after["hygiene"] >= 3:
            reward += 0.5 * self.goal_weights["hygiene"]
        
        if state_after["happiness"] >= 4:
            reward += 1.5 * self.goal_weights["happiness"]
        elif state_after["happiness"] >= 3:
            reward += 1.0 * self.goal_weights["happiness"]
        
        # å½¢çŠ¶å¥–åŠ±ï¼šé¼“åŠ±çŠ¶æ€æ”¹å–„
        if "health_trend" in state_after and state_after["health_trend"] == 1:
            reward += 0.3
        elif "health_trend" in state_after and state_after["health_trend"] == -1:
            reward -= 0.2
        
        if "hunger_trend" in state_after and state_after["hunger_trend"] == -1:
            reward += 0.3
        elif "hunger_trend" in state_after and state_after["hunger_trend"] == 1:
            reward -= 0.2
        
        if "energy_trend" in state_after and state_after["energy_trend"] == 1:
            reward += 0.2
        
        # æƒ©ç½šï¼šä¸è‰¯çŠ¶æ€
        if state_after["health"] <= 0:
            reward -= 3.0 * self.goal_weights["health"]
        elif state_after["health"] <= 1:
            reward -= 1.5 * self.goal_weights["health"]
        
        if state_after["hunger"] >= 5:
            reward -= 2.0 * self.goal_weights["hunger"]
        elif state_after["hunger"] >= 4:
            reward -= 1.0 * self.goal_weights["hunger"]
        
        if state_after["energy"] <= 0:
            reward -= 1.5 * self.goal_weights["energy"]
        elif state_after["energy"] <= 1:
            reward -= 0.8 * self.goal_weights["energy"]
        
        if state_after["hygiene"] <= 0:
            reward -= 1.0 * self.goal_weights["hygiene"]
        elif state_after["hygiene"] <= 1:
            reward -= 0.5 * self.goal_weights["hygiene"]
        
        if state_after["happiness"] <= 0:
            reward -= 1.5 * self.goal_weights["happiness"]
        elif state_after["happiness"] <= 1:
            reward -= 0.8 * self.goal_weights["happiness"]
        
        # ç‰¹æ®ŠçŠ¶æ€å¥–åŠ±/æƒ©ç½š
        if state_after["is_sick"]:
            reward -= 3.0
        
        if state_after["is_sleeping"] and state_after["energy"] < 3:
            reward += 0.8
        
        # å¿ƒæƒ…å¥–åŠ±
        if state_after["mood"] >= 5:
            reward += 0.5
        elif state_after["mood"] <= 1:
            reward -= 0.5
        
        # åŠ¨ä½œç‰¹å®šå¥–åŠ±ï¼ˆæ›´ç²¾ç»†ï¼‰
        if action == "feed" and state_after["hunger"] < state_before["hunger"]:
            reward += 1.2
        if action == "play" and state_after["happiness"] > state_before["happiness"]:
            reward += 1.0
        if action == "sleep" and state_after["energy"] > state_before["energy"]:
            reward += 0.8
        if action == "clean" and state_after["hygiene"] > state_before["hygiene"]:
            reward += 0.6
        if action == "train" and any(skill > 1 for skill in self.pet.skills.values()):
            reward += 0.5 * self.goal_weights["growth"]
        if action == "explore":
            reward += 0.3
        if action == "rest" and state_after["health"] > state_before["health"]:
            reward += 0.7
        
        # å†…åœ¨åŠ¨æœºï¼šå¥½å¥‡å¿ƒå¥–åŠ±ï¼ˆä½¿ç”¨ç®€åŒ–ç‰ˆæœ¬ï¼Œä¸ä¾èµ–çŠ¶æ€å…ƒç»„ï¼‰
        curiosity_reward = self._calculate_curiosity_reward_simple(action)
        reward += curiosity_reward * self.curiosity_bonus
        
        return reward
    
    def _calculate_curiosity_reward_simple(self, action):
        """è®¡ç®—å¥½å¥‡å¿ƒå¥–åŠ±ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼ŒåŸºäºåŠ¨ä½œè®¿é—®é¢‘ç‡ï¼‰"""
        visit_count = self.visitation_counts.get(action, 0)
        if visit_count == 0:
            return 1.0
        else:
            return 1.0 / (1 + visit_count * 0.1)
    
    def learn(self, state_before, action, reward, state_after, done):
        """æ‰§è¡ŒåŒQ-learningå­¦ä¹ """
        # å­˜å‚¨ç»éªŒ
        experience = (state_before, action, reward, state_after, done)
        self.replay_buffer.append(experience)
        
        # è®¡ç®—ä¼˜å…ˆçº§ï¼ˆåŸºäºTDè¯¯å·®ï¼‰
        priority = self._calculate_priority(state_before, action, reward, state_after, done)
        self.priorities.append(priority)
        
        # é™åˆ¶ç¼“å†²åŒºå¤§å°
        if len(self.replay_buffer) > self.buffer_size:
            self.replay_buffer.pop(0)
            self.priorities.pop(0)
        
        # ä¼˜å…ˆç»éªŒå›æ”¾é‡‡æ ·
        batch_size = min(32, len(self.replay_buffer))
        batch_indices = self._prioritized_sample(batch_size)
        batch = [self.replay_buffer[i] for i in batch_indices]
        
        for s, a, r, s_next, d in batch:
            # ç¡®ä¿çŠ¶æ€æ˜¯å¯å“ˆå¸Œçš„å…ƒç»„
            if isinstance(s, list):
                s = tuple(s)
            if isinstance(s_next, list):
                s_next = tuple(s_next)
            
            # åŒQå­¦ä¹ æ›´æ–°
            if random.random() < 0.5:
                # æ›´æ–°Qè¡¨1
                best_action = max(self.q_table_2[s_next], key=self.q_table_2[s_next].get) if self.q_table_2[s_next] else a
                if d:
                    target_q = r
                else:
                    target_q = r + self.discount_factor * self.q_table_1[s_next].get(best_action, 0)
                
                current_q = self.q_table_1[s].get(a, 0)
                new_q = current_q + self.learning_rate * (target_q - current_q)
                self.q_table_1[s][a] = new_q
            else:
                # æ›´æ–°Qè¡¨2
                best_action = max(self.q_table_1[s_next], key=self.q_table_1[s_next].get) if self.q_table_1[s_next] else a
                if d:
                    target_q = r
                else:
                    target_q = r + self.discount_factor * self.q_table_2[s_next].get(best_action, 0)
                
                current_q = self.q_table_2[s].get(a, 0)
                new_q = current_q + self.learning_rate * (target_q - current_q)
                self.q_table_2[s][a] = new_q
        
        # è¡°å‡æ¢ç´¢ç‡
        self.exploration_rate = max(self.min_exploration, self.exploration_rate * self.exploration_decay)
        
        # æ›´æ–°å­¦ä¹ ç»Ÿè®¡
        self.learning_steps += 1
        self.total_reward += reward
        self.average_reward = self.total_reward / self.learning_steps
        self.episode_rewards.append(reward)
        
        return reward
    
    def _calculate_priority(self, state, action, reward, next_state, done):
        """è®¡ç®—ç»éªŒä¼˜å…ˆçº§"""
        # ç¡®ä¿çŠ¶æ€æ˜¯å¯å“ˆå¸Œçš„å…ƒç»„
        if isinstance(state, list):
            state = tuple(state)
        if isinstance(next_state, list):
            next_state = tuple(next_state)
        
        # åˆå¹¶Qå€¼
        q1 = self.q_table_1[state].get(action, 0)
        q2 = self.q_table_2[state].get(action, 0)
        current_q = (q1 + q2) / 2
        
        # è®¡ç®—ç›®æ ‡Qå€¼
        if done:
            target_q = reward
        else:
            best_action = max(self.q_table_1[next_state], key=self.q_table_1[next_state].get) if self.q_table_1[next_state] else action
            next_q = self.q_table_2[next_state].get(best_action, 0)
            target_q = reward + self.discount_factor * next_q
        
        # TDè¯¯å·®
        td_error = abs(target_q - current_q)
        return td_error + 0.01  # æ·»åŠ å°å¸¸æ•°é¿å…é›¶ä¼˜å…ˆçº§
    
    def _prioritized_sample(self, batch_size):
        """åŸºäºä¼˜å…ˆçº§çš„é‡‡æ ·"""
        if len(self.priorities) == 0 or len(self.replay_buffer) == 0:
            return list(range(min(batch_size, len(self.replay_buffer))))
        
        # ç¡®ä¿ priorities å’Œ replay_buffer é•¿åº¦ä¸€è‡´
        min_length = min(len(self.priorities), len(self.replay_buffer))
        if min_length < len(self.priorities):
            self.priorities = self.priorities[:min_length]
        if min_length < len(self.replay_buffer):
            self.replay_buffer = self.replay_buffer[:min_length]
        
        # å½’ä¸€åŒ–ä¼˜å…ˆçº§
        priorities = np.array(self.priorities)
        probabilities = priorities / priorities.sum()
        
        # åŸºäºæ¦‚ç‡é‡‡æ ·
        indices = np.random.choice(len(self.replay_buffer), size=min(batch_size, len(self.replay_buffer)), 
                                   replace=False, p=probabilities)
        return indices.tolist()
    
    def get_learning_stats(self):
        """è·å–å­¦ä¹ ç»Ÿè®¡ä¿¡æ¯"""
        q_table_1_size = sum(len(v) for v in self.q_table_1.values())
        q_table_2_size = sum(len(v) for v in self.q_table_2.values())
        
        return {
            "learning_steps": self.learning_steps,
            "total_reward": self.total_reward,
            "average_reward": self.average_reward,
            "exploration_rate": self.exploration_rate,
            "buffer_size": len(self.replay_buffer),
            "q_table_1_size": q_table_1_size,
            "q_table_2_size": q_table_2_size,
            "total_states": len(set(self.q_table_1.keys()) | set(self.q_table_2.keys())),
            "curiosity_bonus": self.curiosity_bonus,
            "goal_weights": self.goal_weights.copy()
        }
    
    def save_learning_data(self, filename):
        """ä¿å­˜å­¦ä¹ æ•°æ®"""
        data = {
            "q_table_1": {str(k): v for k, v in self.q_table_1.items()},
            "q_table_2": {str(k): v for k, v in self.q_table_2.items()},
            "learning_steps": self.learning_steps,
            "total_reward": self.total_reward,
            "exploration_rate": self.exploration_rate,
            "replay_buffer": self.replay_buffer,
            "priorities": self.priorities,
            "visitation_counts": {str(k): v for k, v in self.visitation_counts.items()},
            "curiosity_bonus": self.curiosity_bonus,
            "goal_weights": self.goal_weights,
            "episode_rewards": self.episode_rewards
        }
        
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        
        return True
    
    def load_learning_data(self, filename):
        """åŠ è½½å­¦ä¹ æ•°æ®"""
        try:
            with open(filename, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            # é€’å½’å°†åˆ—è¡¨è½¬æ¢ä¸ºå…ƒç»„
            def list_to_tuple(obj):
                if isinstance(obj, list):
                    return tuple(list_to_tuple(item) for item in obj)
                return obj
            
            # æ¢å¤Qè¡¨1
            self.q_table_1 = defaultdict(lambda: defaultdict(float))
            for state_str, actions in data.get("q_table_1", {}).items():
                state = eval(state_str)
                # ç¡®ä¿çŠ¶æ€æ˜¯å¯å“ˆå¸Œçš„å…ƒç»„
                state = list_to_tuple(state)
                self.q_table_1[state] = defaultdict(float, actions)
            
            # æ¢å¤Qè¡¨2
            self.q_table_2 = defaultdict(lambda: defaultdict(float))
            for state_str, actions in data.get("q_table_2", {}).items():
                state = eval(state_str)
                # ç¡®ä¿çŠ¶æ€æ˜¯å¯å“ˆå¸Œçš„å…ƒç»„
                state = list_to_tuple(state)
                self.q_table_2[state] = defaultdict(float, actions)
            
            # æ¢å¤å…¶ä»–å‚æ•°
            self.learning_steps = data.get("learning_steps", 0)
            self.total_reward = data.get("total_reward", 0)
            self.exploration_rate = data.get("exploration_rate", self.exploration_rate)
            
            # é€’å½’å°†åˆ—è¡¨è½¬æ¢ä¸ºå…ƒç»„
            def list_to_tuple(obj):
                if isinstance(obj, list):
                    return tuple(list_to_tuple(item) for item in obj)
                return obj
            
            # æ¢å¤å›æ”¾ç¼“å†²åŒºï¼Œç¡®ä¿çŠ¶æ€æ˜¯å…ƒç»„ï¼ˆå¯å“ˆå¸Œï¼‰
            self.replay_buffer = []
            for experience in data.get("replay_buffer", []):
                if len(experience) == 5:
                    s, a, r, s_next, d = experience
                    # å°†åˆ—è¡¨é€’å½’è½¬æ¢ä¸ºå…ƒç»„
                    s = list_to_tuple(s)
                    s_next = list_to_tuple(s_next)
                    self.replay_buffer.append((s, a, r, s_next, d))
            
            # æ¢å¤ä¼˜å…ˆçº§ï¼Œå¹¶ç¡®ä¿é•¿åº¦ä¸å›æ”¾ç¼“å†²åŒºä¸€è‡´
            self.priorities = data.get("priorities", [])
            if len(self.priorities) > len(self.replay_buffer):
                self.priorities = self.priorities[:len(self.replay_buffer)]
            elif len(self.priorities) < len(self.replay_buffer):
                # å¦‚æœä¼˜å…ˆçº§ä¸è¶³ï¼Œè¡¥å……é»˜è®¤å€¼
                self.priorities.extend([0.01] * (len(self.replay_buffer) - len(self.priorities)))
            
            # æ¢å¤è®¿é—®è®¡æ•°
            self.visitation_counts = defaultdict(int)
            for key_str, count in data.get("visitation_counts", {}).items():
                key = eval(key_str)
                # ç¡®ä¿é”®æ˜¯å¯å“ˆå¸Œçš„å…ƒç»„
                key = list_to_tuple(key)
                self.visitation_counts[key] = count
            
            # æ¢å¤å…¶ä»–å‚æ•°
            self.curiosity_bonus = data.get("curiosity_bonus", 0.1)
            self.goal_weights = data.get("goal_weights", self.goal_weights)
            self.episode_rewards = data.get("episode_rewards", [])
            
            print("ğŸ§  å­¦ä¹ æ•°æ®åŠ è½½æˆåŠŸï¼")
            return True
        except Exception as e:
            print(f"âŒ åŠ è½½å­¦ä¹ æ•°æ®å¤±è´¥: {e}")
            return False


# è¡Œä¸ºæ ‘ç³»ç»Ÿ
class BehaviorTreeNode:
    """è¡Œä¸ºæ ‘èŠ‚ç‚¹åŸºç±»"""
    def __init__(self, name=""):
        self.name = name
    
    def execute(self, pet):
        """æ‰§è¡ŒèŠ‚ç‚¹"""
        raise NotImplementedError

class BehaviorTreeStatus:
    """è¡Œä¸ºæ ‘çŠ¶æ€"""
    SUCCESS = "success"
    FAILURE = "failure"
    RUNNING = "running"

class CompositeNode(BehaviorTreeNode):
    """ç»„åˆèŠ‚ç‚¹åŸºç±»"""
    def __init__(self, name=""):
        super().__init__(name)
        self.children = []
    
    def add_child(self, child):
        """æ·»åŠ å­èŠ‚ç‚¹"""
        self.children.append(child)
        return self

class SequenceNode(CompositeNode):
    """åºåˆ—èŠ‚ç‚¹ - æŒ‰é¡ºåºæ‰§è¡Œå­èŠ‚ç‚¹ï¼Œç›´åˆ°ä¸€ä¸ªå¤±è´¥"""
    def execute(self, pet):
        for child in self.children:
            status = child.execute(pet)
            if status != BehaviorTreeStatus.SUCCESS:
                return status
        return BehaviorTreeStatus.SUCCESS

class SelectorNode(CompositeNode):
    """é€‰æ‹©èŠ‚ç‚¹ - æŒ‰é¡ºåºæ‰§è¡Œå­èŠ‚ç‚¹ï¼Œç›´åˆ°ä¸€ä¸ªæˆåŠŸ"""
    def execute(self, pet):
        for child in self.children:
            status = child.execute(pet)
            if status != BehaviorTreeStatus.FAILURE:
                return status
        return BehaviorTreeStatus.FAILURE

class ParallelNode(CompositeNode):
    """å¹¶è¡ŒèŠ‚ç‚¹ - åŒæ—¶æ‰§è¡Œæ‰€æœ‰å­èŠ‚ç‚¹"""
    def __init__(self, name="", success_threshold=1):
        super().__init__(name)
        self.success_threshold = success_threshold
    
    def execute(self, pet):
        success_count = 0
        failure_count = 0
        
        for child in self.children:
            status = child.execute(pet)
            if status == BehaviorTreeStatus.SUCCESS:
                success_count += 1
            elif status == BehaviorTreeStatus.FAILURE:
                failure_count += 1
        
        if success_count >= self.success_threshold:
            return BehaviorTreeStatus.SUCCESS
        elif failure_count == len(self.children):
            return BehaviorTreeStatus.FAILURE
        else:
            return BehaviorTreeStatus.RUNNING

class DecoratorNode(BehaviorTreeNode):
    """è£…é¥°èŠ‚ç‚¹åŸºç±»"""
    def __init__(self, child, name=""):
        super().__init__(name)
        self.child = child

class InverterNode(DecoratorNode):
    """å–åèŠ‚ç‚¹ - åè½¬å­èŠ‚ç‚¹çš„ç»“æœ"""
    def execute(self, pet):
        status = self.child.execute(pet)
        if status == BehaviorTreeStatus.SUCCESS:
            return BehaviorTreeStatus.FAILURE
        elif status == BehaviorTreeStatus.FAILURE:
            return BehaviorTreeStatus.SUCCESS
        else:
            return status

class RepeaterNode(DecoratorNode):
    """é‡å¤èŠ‚ç‚¹ - é‡å¤æ‰§è¡Œå­èŠ‚ç‚¹"""
    def __init__(self, child, count=-1, name=""):
        super().__init__(child, name)
        self.count = count  # -1 è¡¨ç¤ºæ— é™é‡å¤
        self.current_count = 0
    
    def execute(self, pet):
        if self.count == -1 or self.current_count < self.count:
            status = self.child.execute(pet)
            if status != BehaviorTreeStatus.RUNNING:
                self.current_count += 1
            return BehaviorTreeStatus.RUNNING
        else:
            self.current_count = 0
            return BehaviorTreeStatus.SUCCESS

class SucceederNode(DecoratorNode):
    """æˆåŠŸèŠ‚ç‚¹ - æ€»æ˜¯è¿”å›æˆåŠŸ"""
    def execute(self, pet):
        self.child.execute(pet)
        return BehaviorTreeStatus.SUCCESS

class ConditionNode(BehaviorTreeNode):
    """æ¡ä»¶èŠ‚ç‚¹ - æ£€æŸ¥æ¡ä»¶"""
    def __init__(self, condition_func, name=""):
        super().__init__(name)
        self.condition_func = condition_func
    
    def execute(self, pet):
        if self.condition_func(pet):
            return BehaviorTreeStatus.SUCCESS
        else:
            return BehaviorTreeStatus.FAILURE

class ActionNode(BehaviorTreeNode):
    """è¡Œä¸ºèŠ‚ç‚¹ - æ‰§è¡Œå…·ä½“è¡Œä¸º"""
    def __init__(self, action_func, name=""):
        super().__init__(name)
        self.action_func = action_func
    
    def execute(self, pet):
        result = self.action_func(pet)
        if result:
            return BehaviorTreeStatus.SUCCESS
        else:
            return BehaviorTreeStatus.FAILURE

class BehaviorTree:
    """è¡Œä¸ºæ ‘"""
    def __init__(self, root_node):
        self.root = root_node
    
    def execute(self, pet):
        """æ‰§è¡Œè¡Œä¸ºæ ‘"""
        return self.root.execute(pet)

class BehaviorTreeBuilder:
    """è¡Œä¸ºæ ‘æ„å»ºå™¨"""
    @staticmethod
    def build_pet_behavior_tree():
        """æ„å»ºå® ç‰©è¡Œä¸ºæ ‘"""
        # å¥åº·æ£€æŸ¥åºåˆ—
        health_check = SequenceNode("å¥åº·æ£€æŸ¥")
        health_check.add_child(ConditionNode(lambda p: p.health < 30, "å¥åº·ä½äº30"))
        health_check.add_child(ActionNode(lambda p: p.rest(), "ä¼‘æ¯æ¢å¤"))
        
        # é¥¥é¥¿æ£€æŸ¥åºåˆ—
        hunger_check = SequenceNode("é¥¥é¥¿æ£€æŸ¥")
        hunger_check.add_child(ConditionNode(lambda p: p.hunger > 70, "é¥¥é¥¿é«˜äº70"))
        hunger_check.add_child(ActionNode(lambda p: p.beg_for_food(), "ä¹è®¨é£Ÿç‰©"))
        
        # èƒ½é‡æ£€æŸ¥åºåˆ—
        energy_check = SequenceNode("èƒ½é‡æ£€æŸ¥")
        energy_check.add_child(ConditionNode(lambda p: p.energy < 20, "èƒ½é‡ä½äº20"))
        energy_check.add_child(ActionNode(lambda p: p.sleep(), "ç¡è§‰æ¢å¤"))
        
        # æ¸…æ´æ£€æŸ¥åºåˆ—
        hygiene_check = SequenceNode("æ¸…æ´æ£€æŸ¥")
        hygiene_check.add_child(ConditionNode(lambda p: p.hygiene < 30, "æ¸…æ´ä½äº30"))
        hygiene_check.add_child(ActionNode(lambda p: p.groom(), "è‡ªæˆ‘æ¸…æ´"))
        
        # å¿«ä¹æ£€æŸ¥åºåˆ—
        happiness_check = SequenceNode("å¿«ä¹æ£€æŸ¥")
        happiness_check.add_child(ConditionNode(lambda p: p.happiness < 30, "å¿«ä¹ä½äº30"))
        happiness_check.add_child(ActionNode(lambda p: p.spontaneous_play(), "è‡ªå‘ç©è€"))
        
        # ä¸»è¦è¡Œä¸ºé€‰æ‹©å™¨
        main_selector = SelectorNode("ä¸»è¦è¡Œä¸ºé€‰æ‹©")
        main_selector.add_child(health_check)
        main_selector.add_child(hunger_check)
        main_selector.add_child(energy_check)
        main_selector.add_child(hygiene_check)
        main_selector.add_child(happiness_check)
        
        # æ¢ç´¢è¡Œä¸º
        exploration = SequenceNode("æ¢ç´¢è¡Œä¸º")
        exploration.add_child(ConditionNode(lambda p: p.energy > 40, "èƒ½é‡é«˜äº40"))
        exploration.add_child(ActionNode(lambda p: p.explore(), "æ¢ç´¢ç¯å¢ƒ"))
        
        # æœ€ç»ˆè¡Œä¸ºé€‰æ‹©å™¨
        final_selector = SelectorNode("æœ€ç»ˆè¡Œä¸ºé€‰æ‹©")
        final_selector.add_child(main_selector)
        final_selector.add_child(exploration)
        final_selector.add_child(ActionNode(lambda p: p.rest(), "é»˜è®¤ä¼‘æ¯"))
        
        return BehaviorTree(final_selector)